{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdec207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2346, 225, 1, 1)\n",
      "(2346, 4)\n",
      "(807, 225, 1, 1)\n",
      "(807, 4)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 223, 32)           96        \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 111, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 109, 64)           6144      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 54, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3456)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 3456)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 13828     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,068\n",
      "Trainable params: 20,068\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.9645 - accuracy: 0.3008 - val_loss: 1.5934 - val_accuracy: 0.3234\n",
      "Epoch 2/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6.8661 - accuracy: 0.3529 - val_loss: 5.2653 - val_accuracy: 0.5617\n",
      "Epoch 3/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 21.8963 - accuracy: 0.3311 - val_loss: 8.6346 - val_accuracy: 0.3234\n",
      "Epoch 4/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 50.8277 - accuracy: 0.3534 - val_loss: 23.0848 - val_accuracy: 0.4638\n",
      "Epoch 5/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 92.1209 - accuracy: 0.3515 - val_loss: 33.4366 - val_accuracy: 0.3234\n",
      "Epoch 6/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 136.0071 - accuracy: 0.3458 - val_loss: 85.0204 - val_accuracy: 0.4638\n",
      "Epoch 7/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 198.1303 - accuracy: 0.3468 - val_loss: 102.2098 - val_accuracy: 0.2936\n",
      "Epoch 8/1000\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 294.1393 - accuracy: 0.3288 - val_loss: 155.0582 - val_accuracy: 0.3234\n",
      "Epoch 9/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 368.1246 - accuracy: 0.3373 - val_loss: 235.0174 - val_accuracy: 0.4213\n",
      "Epoch 10/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 460.7255 - accuracy: 0.3401 - val_loss: 301.8733 - val_accuracy: 0.3234\n",
      "Epoch 11/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 596.8018 - accuracy: 0.3505 - val_loss: 307.9878 - val_accuracy: 0.2936\n",
      "Epoch 12/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 759.8327 - accuracy: 0.3453 - val_loss: 226.1957 - val_accuracy: 0.3234\n",
      "Epoch 13/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 817.9715 - accuracy: 0.3425 - val_loss: 802.1991 - val_accuracy: 0.3234\n",
      "Epoch 14/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 918.8220 - accuracy: 0.3387 - val_loss: 663.0261 - val_accuracy: 0.3234\n",
      "Epoch 15/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1179.5004 - accuracy: 0.3269 - val_loss: 1009.3098 - val_accuracy: 0.3234\n",
      "Epoch 16/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1291.8369 - accuracy: 0.3382 - val_loss: 1565.1636 - val_accuracy: 0.4213\n",
      "Epoch 17/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1473.8190 - accuracy: 0.3577 - val_loss: 1490.3511 - val_accuracy: 0.3234\n",
      "Epoch 18/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1547.2482 - accuracy: 0.3359 - val_loss: 1240.9377 - val_accuracy: 0.4213\n",
      "Epoch 19/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1669.6534 - accuracy: 0.3330 - val_loss: 1561.6884 - val_accuracy: 0.3234\n",
      "Epoch 20/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 2150.3452 - accuracy: 0.3425 - val_loss: 1568.8287 - val_accuracy: 0.3234\n",
      "Epoch 21/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1940.8716 - accuracy: 0.3534 - val_loss: 2310.9893 - val_accuracy: 0.3234\n",
      "Epoch 22/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 2252.9932 - accuracy: 0.3259 - val_loss: 2874.7212 - val_accuracy: 0.3234\n",
      "Epoch 23/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 2508.5955 - accuracy: 0.3250 - val_loss: 2087.4531 - val_accuracy: 0.4213\n",
      "Epoch 24/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 2643.1582 - accuracy: 0.3340 - val_loss: 2180.2725 - val_accuracy: 0.3234\n",
      "Epoch 25/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 2835.4873 - accuracy: 0.3245 - val_loss: 1858.1128 - val_accuracy: 0.2936\n",
      "Epoch 26/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 3154.4253 - accuracy: 0.3292 - val_loss: 3957.0190 - val_accuracy: 0.4213\n",
      "Epoch 27/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 3282.2393 - accuracy: 0.3392 - val_loss: 5080.0757 - val_accuracy: 0.3234\n",
      "Epoch 28/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 3641.2126 - accuracy: 0.3411 - val_loss: 3491.5339 - val_accuracy: 0.4213\n",
      "Epoch 29/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 3975.7490 - accuracy: 0.3359 - val_loss: 4933.7998 - val_accuracy: 0.3234\n",
      "Epoch 30/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4678.6714 - accuracy: 0.3108 - val_loss: 3153.0425 - val_accuracy: 0.2936\n",
      "Epoch 31/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4223.6821 - accuracy: 0.3382 - val_loss: 4357.3511 - val_accuracy: 0.3234\n",
      "Epoch 32/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4322.3062 - accuracy: 0.3463 - val_loss: 5063.5063 - val_accuracy: 0.3234\n",
      "Epoch 33/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 4444.2104 - accuracy: 0.3202 - val_loss: 4048.0808 - val_accuracy: 0.3234\n",
      "Epoch 34/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 4487.0488 - accuracy: 0.3761 - val_loss: 3872.0574 - val_accuracy: 0.3234\n",
      "Epoch 35/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 5331.5073 - accuracy: 0.3349 - val_loss: 6471.3491 - val_accuracy: 0.3234\n",
      "Epoch 36/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5156.2954 - accuracy: 0.3685 - val_loss: 5957.7041 - val_accuracy: 0.2936\n",
      "Epoch 37/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 5776.3530 - accuracy: 0.3420 - val_loss: 6756.2446 - val_accuracy: 0.4213\n",
      "Epoch 38/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 6707.0410 - accuracy: 0.3283 - val_loss: 6966.0850 - val_accuracy: 0.3234\n",
      "Epoch 39/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 6681.0396 - accuracy: 0.3444 - val_loss: 7692.4551 - val_accuracy: 0.3234\n",
      "Epoch 40/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 6952.5059 - accuracy: 0.3548 - val_loss: 8230.0303 - val_accuracy: 0.4213\n",
      "Epoch 41/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 6692.7241 - accuracy: 0.3425 - val_loss: 8515.4170 - val_accuracy: 0.3234\n",
      "Epoch 42/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 7560.0425 - accuracy: 0.3264 - val_loss: 10038.5703 - val_accuracy: 0.3234\n",
      "Epoch 43/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 6945.2183 - accuracy: 0.3259 - val_loss: 6575.8726 - val_accuracy: 0.3234\n",
      "Epoch 44/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 7576.1978 - accuracy: 0.3425 - val_loss: 10780.7529 - val_accuracy: 0.3234\n",
      "Epoch 45/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 7707.7725 - accuracy: 0.3245 - val_loss: 12648.8975 - val_accuracy: 0.3234\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 7ms/step - loss: 8696.8369 - accuracy: 0.3254 - val_loss: 11172.0381 - val_accuracy: 0.3234\n",
      "Epoch 47/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 8293.7148 - accuracy: 0.3434 - val_loss: 12811.5703 - val_accuracy: 0.3234\n",
      "Epoch 48/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 9216.3652 - accuracy: 0.3520 - val_loss: 12895.9658 - val_accuracy: 0.3234\n",
      "Epoch 49/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 9119.7871 - accuracy: 0.3534 - val_loss: 12275.5576 - val_accuracy: 0.4213\n",
      "Epoch 50/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 9682.2061 - accuracy: 0.3316 - val_loss: 10731.7959 - val_accuracy: 0.2936\n",
      "Epoch 51/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 9932.4082 - accuracy: 0.3396 - val_loss: 13195.9404 - val_accuracy: 0.4213\n",
      "Epoch 52/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 10465.3320 - accuracy: 0.3515 - val_loss: 21908.5273 - val_accuracy: 0.3234\n",
      "Epoch 53/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 10371.0938 - accuracy: 0.3306 - val_loss: 13704.0342 - val_accuracy: 0.4213\n",
      "Epoch 54/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 10780.4014 - accuracy: 0.3354 - val_loss: 17786.8516 - val_accuracy: 0.3234\n",
      "Epoch 55/1000\n",
      "66/66 [==============================] - 0s 8ms/step - loss: 11037.6689 - accuracy: 0.3510 - val_loss: 22361.3027 - val_accuracy: 0.3234\n",
      "Epoch 56/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 11453.5059 - accuracy: 0.3453 - val_loss: 20184.7402 - val_accuracy: 0.3234\n",
      "Epoch 57/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 11732.1426 - accuracy: 0.3387 - val_loss: 15022.0684 - val_accuracy: 0.4213\n",
      "Epoch 58/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 12008.3477 - accuracy: 0.3591 - val_loss: 22278.2891 - val_accuracy: 0.3234\n",
      "Epoch 59/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 12867.6826 - accuracy: 0.3373 - val_loss: 19636.4336 - val_accuracy: 0.3234\n",
      "Epoch 60/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 13540.3027 - accuracy: 0.3221 - val_loss: 20960.1875 - val_accuracy: 0.4213\n",
      "Epoch 61/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 12774.4658 - accuracy: 0.3463 - val_loss: 16764.4766 - val_accuracy: 0.3234\n",
      "Epoch 62/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 13740.7188 - accuracy: 0.3373 - val_loss: 24533.2930 - val_accuracy: 0.3234\n",
      "Epoch 63/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 13970.8955 - accuracy: 0.3486 - val_loss: 18967.9922 - val_accuracy: 0.4213\n",
      "Epoch 64/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 14319.4014 - accuracy: 0.3316 - val_loss: 24055.6934 - val_accuracy: 0.3234\n",
      "Epoch 65/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 13875.9004 - accuracy: 0.3458 - val_loss: 22112.6562 - val_accuracy: 0.4213\n",
      "Epoch 66/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 14618.2334 - accuracy: 0.3430 - val_loss: 21543.7285 - val_accuracy: 0.3234\n",
      "Epoch 67/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 16255.3818 - accuracy: 0.3415 - val_loss: 20265.0039 - val_accuracy: 0.3234\n",
      "Epoch 68/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 15794.0254 - accuracy: 0.3458 - val_loss: 19277.1406 - val_accuracy: 0.4213\n",
      "Epoch 69/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 15781.3203 - accuracy: 0.3354 - val_loss: 22929.5488 - val_accuracy: 0.4213\n",
      "Epoch 70/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 18083.9941 - accuracy: 0.3515 - val_loss: 23490.6719 - val_accuracy: 0.4213\n",
      "Epoch 71/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 17641.5391 - accuracy: 0.3425 - val_loss: 24683.3184 - val_accuracy: 0.3234\n",
      "Epoch 72/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 17874.2734 - accuracy: 0.3468 - val_loss: 20340.9023 - val_accuracy: 0.3234\n",
      "Epoch 73/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 19573.0723 - accuracy: 0.3340 - val_loss: 24365.6172 - val_accuracy: 0.3234\n",
      "Epoch 74/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 18814.4746 - accuracy: 0.3510 - val_loss: 36422.8086 - val_accuracy: 0.3234\n",
      "Epoch 75/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 18041.2559 - accuracy: 0.3430 - val_loss: 22231.2852 - val_accuracy: 0.2936\n",
      "Epoch 76/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 18406.5566 - accuracy: 0.3330 - val_loss: 27182.6035 - val_accuracy: 0.2936\n",
      "Epoch 77/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 19599.1328 - accuracy: 0.3510 - val_loss: 30786.5527 - val_accuracy: 0.3234\n",
      "Epoch 78/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 20286.5723 - accuracy: 0.3539 - val_loss: 26864.2051 - val_accuracy: 0.3234\n",
      "Epoch 79/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 19750.6895 - accuracy: 0.3520 - val_loss: 33415.9492 - val_accuracy: 0.3234\n",
      "Epoch 80/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 19592.8398 - accuracy: 0.3335 - val_loss: 26265.1738 - val_accuracy: 0.3234\n",
      "Epoch 81/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 21080.7930 - accuracy: 0.3515 - val_loss: 24639.4902 - val_accuracy: 0.4213\n",
      "Epoch 82/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 22154.6133 - accuracy: 0.3235 - val_loss: 23375.6602 - val_accuracy: 0.2936\n",
      "Epoch 83/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 19240.4453 - accuracy: 0.3449 - val_loss: 34728.1367 - val_accuracy: 0.3234\n",
      "Epoch 84/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 22094.8359 - accuracy: 0.3477 - val_loss: 34348.3242 - val_accuracy: 0.3234\n",
      "Epoch 85/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 20619.1230 - accuracy: 0.3605 - val_loss: 37654.8242 - val_accuracy: 0.3234\n",
      "Epoch 86/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 22638.3809 - accuracy: 0.3411 - val_loss: 35569.5312 - val_accuracy: 0.4213\n",
      "Epoch 87/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 22253.2852 - accuracy: 0.3278 - val_loss: 38053.1055 - val_accuracy: 0.3234\n",
      "Epoch 88/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 21729.3086 - accuracy: 0.3548 - val_loss: 35823.2852 - val_accuracy: 0.4213\n",
      "Epoch 89/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 23615.7188 - accuracy: 0.3581 - val_loss: 43985.7344 - val_accuracy: 0.3234\n",
      "Epoch 90/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 25079.5215 - accuracy: 0.3439 - val_loss: 28989.6504 - val_accuracy: 0.4213\n",
      "Epoch 91/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 22969.2832 - accuracy: 0.3387 - val_loss: 46269.9922 - val_accuracy: 0.3234\n",
      "Epoch 92/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 24376.1445 - accuracy: 0.3235 - val_loss: 36097.3945 - val_accuracy: 0.3234\n",
      "Epoch 93/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 24320.8652 - accuracy: 0.3354 - val_loss: 40886.9102 - val_accuracy: 0.3234\n",
      "Epoch 94/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 25064.9980 - accuracy: 0.3354 - val_loss: 44513.3945 - val_accuracy: 0.3234\n",
      "Epoch 95/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 25414.2148 - accuracy: 0.3349 - val_loss: 33703.2852 - val_accuracy: 0.3234\n",
      "Epoch 96/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 26802.5234 - accuracy: 0.3254 - val_loss: 31882.6211 - val_accuracy: 0.3234\n",
      "Epoch 97/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 26292.2480 - accuracy: 0.3595 - val_loss: 39664.3047 - val_accuracy: 0.4213\n",
      "Epoch 98/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 28525.0293 - accuracy: 0.3486 - val_loss: 40357.3789 - val_accuracy: 0.4213\n",
      "Epoch 99/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 29868.4824 - accuracy: 0.3292 - val_loss: 39792.6797 - val_accuracy: 0.4213\n",
      "Epoch 100/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 27521.1816 - accuracy: 0.3515 - val_loss: 32968.3750 - val_accuracy: 0.3234\n",
      "Epoch 101/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 27401.1445 - accuracy: 0.3463 - val_loss: 48786.7930 - val_accuracy: 0.3234\n",
      "Epoch 102/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 27484.1426 - accuracy: 0.3278 - val_loss: 55941.5508 - val_accuracy: 0.3234\n",
      "Epoch 103/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 29748.6113 - accuracy: 0.3515 - val_loss: 34793.2266 - val_accuracy: 0.4213\n",
      "Epoch 104/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 29893.6426 - accuracy: 0.3325 - val_loss: 47149.0391 - val_accuracy: 0.3234\n",
      "Epoch 105/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 28481.0527 - accuracy: 0.3624 - val_loss: 39495.9648 - val_accuracy: 0.4213\n",
      "Epoch 106/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 30449.6484 - accuracy: 0.3482 - val_loss: 46528.0000 - val_accuracy: 0.3234\n",
      "Epoch 107/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 31361.1523 - accuracy: 0.3363 - val_loss: 42783.0117 - val_accuracy: 0.4213\n",
      "Epoch 108/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 29400.2734 - accuracy: 0.3392 - val_loss: 40666.6211 - val_accuracy: 0.4213\n",
      "Epoch 109/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 30897.0469 - accuracy: 0.3378 - val_loss: 40620.4258 - val_accuracy: 0.3234\n",
      "Epoch 110/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 31822.8672 - accuracy: 0.3543 - val_loss: 41112.0352 - val_accuracy: 0.4213\n",
      "Epoch 111/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 30506.6875 - accuracy: 0.3472 - val_loss: 53820.1523 - val_accuracy: 0.3234\n",
      "Epoch 112/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 32184.3672 - accuracy: 0.3449 - val_loss: 35709.7539 - val_accuracy: 0.4213\n",
      "Epoch 113/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 33331.3398 - accuracy: 0.3406 - val_loss: 43151.5898 - val_accuracy: 0.3234\n",
      "Epoch 114/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 34990.1406 - accuracy: 0.3373 - val_loss: 52608.9531 - val_accuracy: 0.3234\n",
      "Epoch 115/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 32615.1621 - accuracy: 0.3164 - val_loss: 50544.8164 - val_accuracy: 0.3234\n",
      "Epoch 116/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 33455.7148 - accuracy: 0.3600 - val_loss: 34576.9883 - val_accuracy: 0.2936\n",
      "Epoch 117/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 33846.9961 - accuracy: 0.3340 - val_loss: 42754.3164 - val_accuracy: 0.3234\n",
      "Epoch 118/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 34762.3477 - accuracy: 0.3306 - val_loss: 56154.2812 - val_accuracy: 0.3234\n",
      "Epoch 119/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 33814.7891 - accuracy: 0.3411 - val_loss: 42866.4492 - val_accuracy: 0.4213\n",
      "Epoch 120/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 35893.3281 - accuracy: 0.3425 - val_loss: 52308.4922 - val_accuracy: 0.4213\n",
      "Epoch 121/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 36417.8008 - accuracy: 0.3453 - val_loss: 54267.3008 - val_accuracy: 0.3234\n",
      "Epoch 122/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 37240.4062 - accuracy: 0.3245 - val_loss: 48117.1055 - val_accuracy: 0.3234\n",
      "Epoch 123/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 37996.7227 - accuracy: 0.3359 - val_loss: 38943.1836 - val_accuracy: 0.2936\n",
      "Epoch 124/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 36147.2422 - accuracy: 0.3458 - val_loss: 41693.6836 - val_accuracy: 0.4213\n",
      "Epoch 125/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 37766.2969 - accuracy: 0.3325 - val_loss: 36952.4414 - val_accuracy: 0.2936\n",
      "Epoch 126/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 37810.6328 - accuracy: 0.3439 - val_loss: 49621.9922 - val_accuracy: 0.3234\n",
      "Epoch 127/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 43079.8750 - accuracy: 0.3216 - val_loss: 52315.7773 - val_accuracy: 0.3234\n",
      "Epoch 128/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 40844.8828 - accuracy: 0.3392 - val_loss: 35962.1445 - val_accuracy: 0.2936\n",
      "Epoch 129/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 40521.1602 - accuracy: 0.3477 - val_loss: 43215.1836 - val_accuracy: 0.4213\n",
      "Epoch 130/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 41178.3516 - accuracy: 0.3510 - val_loss: 79238.6016 - val_accuracy: 0.3234\n",
      "Epoch 131/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 44522.6055 - accuracy: 0.3368 - val_loss: 59903.2500 - val_accuracy: 0.4213\n",
      "Epoch 132/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 49752.6992 - accuracy: 0.3406 - val_loss: 70086.2656 - val_accuracy: 0.3234\n",
      "Epoch 133/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 42330.3984 - accuracy: 0.3486 - val_loss: 47640.3047 - val_accuracy: 0.4213\n",
      "Epoch 134/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 43277.1836 - accuracy: 0.3411 - val_loss: 56414.2305 - val_accuracy: 0.3234\n",
      "Epoch 135/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 40546.7656 - accuracy: 0.3595 - val_loss: 70772.3594 - val_accuracy: 0.3234\n",
      "Epoch 136/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 44956.3008 - accuracy: 0.3382 - val_loss: 83511.0156 - val_accuracy: 0.3234\n",
      "Epoch 137/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 43541.4883 - accuracy: 0.3477 - val_loss: 61659.5078 - val_accuracy: 0.3234\n",
      "Epoch 138/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 43613.8086 - accuracy: 0.3548 - val_loss: 82988.8672 - val_accuracy: 0.3234\n",
      "Epoch 139/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 49469.1445 - accuracy: 0.3335 - val_loss: 76274.5156 - val_accuracy: 0.3234\n",
      "Epoch 140/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 49389.0977 - accuracy: 0.3311 - val_loss: 53075.3359 - val_accuracy: 0.4213\n",
      "Epoch 141/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 47281.2969 - accuracy: 0.3567 - val_loss: 66446.3672 - val_accuracy: 0.3234\n",
      "Epoch 142/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 45642.1953 - accuracy: 0.3411 - val_loss: 66574.9141 - val_accuracy: 0.3234\n",
      "Epoch 143/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 47040.9688 - accuracy: 0.3150 - val_loss: 84612.6953 - val_accuracy: 0.3234\n",
      "Epoch 144/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 49017.7461 - accuracy: 0.3316 - val_loss: 71947.5078 - val_accuracy: 0.3234\n",
      "Epoch 145/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 45057.0820 - accuracy: 0.3529 - val_loss: 73863.1484 - val_accuracy: 0.3234\n",
      "Epoch 146/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 48602.3828 - accuracy: 0.3387 - val_loss: 59556.0859 - val_accuracy: 0.4213\n",
      "Epoch 147/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 46774.1172 - accuracy: 0.3444 - val_loss: 80579.8125 - val_accuracy: 0.3234\n",
      "Epoch 148/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 48461.2578 - accuracy: 0.3439 - val_loss: 69312.0000 - val_accuracy: 0.4213\n",
      "Epoch 149/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 54182.7773 - accuracy: 0.3273 - val_loss: 89496.2422 - val_accuracy: 0.3234\n",
      "Epoch 150/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 56054.0117 - accuracy: 0.3619 - val_loss: 83239.7578 - val_accuracy: 0.3234\n",
      "Epoch 151/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 56004.1992 - accuracy: 0.3306 - val_loss: 74441.8047 - val_accuracy: 0.4213\n",
      "Epoch 152/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 52715.4766 - accuracy: 0.3624 - val_loss: 91485.4141 - val_accuracy: 0.3234\n",
      "Epoch 153/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 50332.3164 - accuracy: 0.3501 - val_loss: 78845.0703 - val_accuracy: 0.3234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 52413.6367 - accuracy: 0.3373 - val_loss: 74037.5859 - val_accuracy: 0.3234\n",
      "Epoch 155/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 55530.3672 - accuracy: 0.3254 - val_loss: 80566.6016 - val_accuracy: 0.3234\n",
      "Epoch 156/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 55570.0703 - accuracy: 0.3330 - val_loss: 74348.3906 - val_accuracy: 0.3234\n",
      "Epoch 157/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 55047.0938 - accuracy: 0.3406 - val_loss: 94860.5312 - val_accuracy: 0.3234\n",
      "Epoch 158/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 52956.9453 - accuracy: 0.3472 - val_loss: 79292.5938 - val_accuracy: 0.3234\n",
      "Epoch 159/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 56693.2695 - accuracy: 0.3406 - val_loss: 98525.4141 - val_accuracy: 0.3234\n",
      "Epoch 160/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 60436.6836 - accuracy: 0.3316 - val_loss: 76811.7109 - val_accuracy: 0.3234\n",
      "Epoch 161/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 62354.8438 - accuracy: 0.3539 - val_loss: 64174.2969 - val_accuracy: 0.2936\n",
      "Epoch 162/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 56964.9336 - accuracy: 0.3278 - val_loss: 105092.3594 - val_accuracy: 0.3234\n",
      "Epoch 163/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 61151.8555 - accuracy: 0.3434 - val_loss: 68976.8828 - val_accuracy: 0.4213\n",
      "Epoch 164/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 65478.5703 - accuracy: 0.3373 - val_loss: 102133.6484 - val_accuracy: 0.3234\n",
      "Epoch 165/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 59419.7617 - accuracy: 0.3373 - val_loss: 94692.6328 - val_accuracy: 0.4213\n",
      "Epoch 166/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 60565.2383 - accuracy: 0.3425 - val_loss: 114845.5469 - val_accuracy: 0.3234\n",
      "Epoch 167/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 60849.5977 - accuracy: 0.3652 - val_loss: 110308.7656 - val_accuracy: 0.3234\n",
      "Epoch 168/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 61332.6602 - accuracy: 0.3534 - val_loss: 85655.5547 - val_accuracy: 0.3234\n",
      "Epoch 169/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 64833.6289 - accuracy: 0.3567 - val_loss: 111281.4297 - val_accuracy: 0.3234\n",
      "Epoch 170/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 59130.1016 - accuracy: 0.3605 - val_loss: 82678.6016 - val_accuracy: 0.3234\n",
      "Epoch 171/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 62265.2227 - accuracy: 0.3415 - val_loss: 76384.8203 - val_accuracy: 0.3234\n",
      "Epoch 172/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 65189.8516 - accuracy: 0.3207 - val_loss: 80924.5938 - val_accuracy: 0.3234\n",
      "Epoch 173/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 64050.7227 - accuracy: 0.3548 - val_loss: 76374.0625 - val_accuracy: 0.4213\n",
      "Epoch 174/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 67100.1406 - accuracy: 0.3449 - val_loss: 98021.9922 - val_accuracy: 0.3234\n",
      "Epoch 175/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 64439.6016 - accuracy: 0.3420 - val_loss: 86320.4766 - val_accuracy: 0.3234\n",
      "Epoch 176/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 68594.4141 - accuracy: 0.3406 - val_loss: 100362.2109 - val_accuracy: 0.4213\n",
      "Epoch 177/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 66685.5156 - accuracy: 0.3449 - val_loss: 64666.5547 - val_accuracy: 0.4213\n",
      "Epoch 178/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 65094.8672 - accuracy: 0.3520 - val_loss: 113399.4219 - val_accuracy: 0.3234\n",
      "Epoch 179/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 68584.9453 - accuracy: 0.3306 - val_loss: 98030.5703 - val_accuracy: 0.3234\n",
      "Epoch 180/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 67271.3047 - accuracy: 0.3283 - val_loss: 83658.0781 - val_accuracy: 0.3234\n",
      "Epoch 181/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 68680.0156 - accuracy: 0.3534 - val_loss: 87565.0703 - val_accuracy: 0.4213\n",
      "Epoch 182/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 67829.6797 - accuracy: 0.3524 - val_loss: 127317.3750 - val_accuracy: 0.3234\n",
      "Epoch 183/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 66483.7969 - accuracy: 0.3359 - val_loss: 113226.3516 - val_accuracy: 0.3234\n",
      "Epoch 184/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 74287.6875 - accuracy: 0.3482 - val_loss: 125723.6406 - val_accuracy: 0.3234\n",
      "Epoch 185/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 83022.5078 - accuracy: 0.3387 - val_loss: 104545.0859 - val_accuracy: 0.3234\n",
      "Epoch 186/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 70872.2812 - accuracy: 0.3463 - val_loss: 120443.1016 - val_accuracy: 0.3234\n",
      "Epoch 187/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 78068.9375 - accuracy: 0.3425 - val_loss: 119127.2812 - val_accuracy: 0.4213\n",
      "Epoch 188/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 75823.6719 - accuracy: 0.3439 - val_loss: 90973.5469 - val_accuracy: 0.3234\n",
      "Epoch 189/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 74011.7109 - accuracy: 0.3311 - val_loss: 102592.6797 - val_accuracy: 0.4213\n",
      "Epoch 190/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 76177.2812 - accuracy: 0.3411 - val_loss: 114030.4375 - val_accuracy: 0.3234\n",
      "Epoch 191/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 71501.5859 - accuracy: 0.3496 - val_loss: 89454.2969 - val_accuracy: 0.4213\n",
      "Epoch 192/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 77534.2578 - accuracy: 0.3292 - val_loss: 117666.9922 - val_accuracy: 0.3234\n",
      "Epoch 193/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 80082.0391 - accuracy: 0.3477 - val_loss: 101374.2266 - val_accuracy: 0.4213\n",
      "Epoch 194/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 76154.0156 - accuracy: 0.3306 - val_loss: 131637.5156 - val_accuracy: 0.3234\n",
      "Epoch 195/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 77721.0703 - accuracy: 0.3382 - val_loss: 114330.2812 - val_accuracy: 0.4213\n",
      "Epoch 196/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 82999.7266 - accuracy: 0.3174 - val_loss: 135565.4844 - val_accuracy: 0.3234\n",
      "Epoch 197/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 79803.6484 - accuracy: 0.3468 - val_loss: 109279.1797 - val_accuracy: 0.3234\n",
      "Epoch 198/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 79593.8359 - accuracy: 0.3396 - val_loss: 122904.1016 - val_accuracy: 0.3234\n",
      "Epoch 199/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 82702.6719 - accuracy: 0.3477 - val_loss: 137158.2656 - val_accuracy: 0.4213\n",
      "Epoch 200/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 73226.2031 - accuracy: 0.3411 - val_loss: 138771.8750 - val_accuracy: 0.3234\n",
      "Epoch 201/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 80659.2031 - accuracy: 0.3439 - val_loss: 170472.9844 - val_accuracy: 0.3234\n",
      "Epoch 202/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 88069.7266 - accuracy: 0.3406 - val_loss: 88142.9766 - val_accuracy: 0.1021\n",
      "Epoch 203/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 78677.5703 - accuracy: 0.3344 - val_loss: 130175.7266 - val_accuracy: 0.3234\n",
      "Epoch 204/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 81675.7812 - accuracy: 0.3411 - val_loss: 126337.0859 - val_accuracy: 0.3234\n",
      "Epoch 205/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 82418.8125 - accuracy: 0.3363 - val_loss: 146577.7031 - val_accuracy: 0.2936\n",
      "Epoch 206/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 82772.8594 - accuracy: 0.3406 - val_loss: 113248.9531 - val_accuracy: 0.3830\n",
      "Epoch 207/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 84640.1797 - accuracy: 0.3600 - val_loss: 138037.9219 - val_accuracy: 0.4213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 102605.2188 - accuracy: 0.3297 - val_loss: 162610.3906 - val_accuracy: 0.3234\n",
      "Epoch 209/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 88898.8672 - accuracy: 0.3444 - val_loss: 148390.9375 - val_accuracy: 0.3234\n",
      "Epoch 210/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 87125.4062 - accuracy: 0.3648 - val_loss: 146076.5938 - val_accuracy: 0.4213\n",
      "Epoch 211/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 89842.8125 - accuracy: 0.3344 - val_loss: 142175.5938 - val_accuracy: 0.2936\n",
      "Epoch 212/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 93247.1797 - accuracy: 0.3288 - val_loss: 152730.1406 - val_accuracy: 0.4213\n",
      "Epoch 213/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 91078.1094 - accuracy: 0.3411 - val_loss: 120118.1953 - val_accuracy: 0.3234\n",
      "Epoch 214/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 87536.8984 - accuracy: 0.3378 - val_loss: 135934.6406 - val_accuracy: 0.3234\n",
      "Epoch 215/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 92430.5078 - accuracy: 0.3335 - val_loss: 170715.2344 - val_accuracy: 0.4213\n",
      "Epoch 216/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 102671.2969 - accuracy: 0.3453 - val_loss: 163179.8438 - val_accuracy: 0.4213\n",
      "Epoch 217/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 89594.2422 - accuracy: 0.3321 - val_loss: 150112.9531 - val_accuracy: 0.3234\n",
      "Epoch 218/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 86352.7344 - accuracy: 0.3363 - val_loss: 155514.5469 - val_accuracy: 0.3234\n",
      "Epoch 219/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 95997.8750 - accuracy: 0.3278 - val_loss: 161640.3125 - val_accuracy: 0.3234\n",
      "Epoch 220/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 98841.1953 - accuracy: 0.3169 - val_loss: 167155.4688 - val_accuracy: 0.3234\n",
      "Epoch 221/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 90119.6250 - accuracy: 0.3306 - val_loss: 147702.2031 - val_accuracy: 0.4213\n",
      "Epoch 222/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 87527.0156 - accuracy: 0.3581 - val_loss: 140938.6250 - val_accuracy: 0.4213\n",
      "Epoch 223/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 92227.6562 - accuracy: 0.3316 - val_loss: 170513.4375 - val_accuracy: 0.3234\n",
      "Epoch 224/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 97429.2344 - accuracy: 0.3387 - val_loss: 107227.5078 - val_accuracy: 0.2936\n",
      "Epoch 225/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 94911.1094 - accuracy: 0.3297 - val_loss: 181193.2656 - val_accuracy: 0.4213\n",
      "Epoch 226/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 91813.2266 - accuracy: 0.3444 - val_loss: 118226.5156 - val_accuracy: 0.2936\n",
      "Epoch 227/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 96868.4844 - accuracy: 0.3477 - val_loss: 195710.6406 - val_accuracy: 0.3234\n",
      "Epoch 228/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 100362.8047 - accuracy: 0.3363 - val_loss: 162993.5625 - val_accuracy: 0.3234\n",
      "Epoch 229/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 94196.7188 - accuracy: 0.3444 - val_loss: 134510.0312 - val_accuracy: 0.3234\n",
      "Epoch 230/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 98294.7969 - accuracy: 0.3359 - val_loss: 155479.4219 - val_accuracy: 0.3234\n",
      "Epoch 231/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 94664.5625 - accuracy: 0.3562 - val_loss: 165899.9844 - val_accuracy: 0.3234\n",
      "Epoch 232/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 96358.0625 - accuracy: 0.3430 - val_loss: 143780.2188 - val_accuracy: 0.3234\n",
      "Epoch 233/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 94299.2266 - accuracy: 0.3411 - val_loss: 158302.7812 - val_accuracy: 0.3234\n",
      "Epoch 234/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 101620.7500 - accuracy: 0.3667 - val_loss: 155975.3594 - val_accuracy: 0.2936\n",
      "Epoch 235/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 108809.9453 - accuracy: 0.3297 - val_loss: 185928.7188 - val_accuracy: 0.4213\n",
      "Epoch 236/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 103986.0859 - accuracy: 0.3292 - val_loss: 144386.4531 - val_accuracy: 0.3234\n",
      "Epoch 237/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 100905.9922 - accuracy: 0.3378 - val_loss: 156035.5469 - val_accuracy: 0.4213\n",
      "Epoch 238/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 101064.6406 - accuracy: 0.3368 - val_loss: 195651.2656 - val_accuracy: 0.3234\n",
      "Epoch 239/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 99887.2969 - accuracy: 0.3425 - val_loss: 160589.8906 - val_accuracy: 0.3234\n",
      "Epoch 240/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 104722.3438 - accuracy: 0.3392 - val_loss: 198413.3438 - val_accuracy: 0.3234\n",
      "Epoch 241/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 107841.7891 - accuracy: 0.3396 - val_loss: 236244.9688 - val_accuracy: 0.3234\n",
      "Epoch 242/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 115362.2578 - accuracy: 0.3553 - val_loss: 188863.7344 - val_accuracy: 0.4213\n",
      "Epoch 243/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 105901.0234 - accuracy: 0.3359 - val_loss: 128491.3047 - val_accuracy: 0.3234\n",
      "Epoch 244/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 116852.8438 - accuracy: 0.3534 - val_loss: 233125.5781 - val_accuracy: 0.3234\n",
      "Epoch 245/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 117483.7188 - accuracy: 0.3515 - val_loss: 164444.3281 - val_accuracy: 0.4213\n",
      "Epoch 246/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 109030.2578 - accuracy: 0.3311 - val_loss: 198332.4531 - val_accuracy: 0.3234\n",
      "Epoch 247/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 111614.3594 - accuracy: 0.3382 - val_loss: 166524.7344 - val_accuracy: 0.4213\n",
      "Epoch 248/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 112893.8750 - accuracy: 0.3245 - val_loss: 144165.0312 - val_accuracy: 0.3234\n",
      "Epoch 249/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 111777.9531 - accuracy: 0.3406 - val_loss: 169498.9688 - val_accuracy: 0.3234\n",
      "Epoch 250/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 109534.3203 - accuracy: 0.3411 - val_loss: 157961.5312 - val_accuracy: 0.4213\n",
      "Epoch 251/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 124878.7344 - accuracy: 0.3363 - val_loss: 152947.7500 - val_accuracy: 0.3234\n",
      "Epoch 252/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 117932.9922 - accuracy: 0.3340 - val_loss: 193492.9688 - val_accuracy: 0.3234\n",
      "Epoch 253/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 115858.3750 - accuracy: 0.3273 - val_loss: 136502.4688 - val_accuracy: 0.3234\n",
      "Epoch 254/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 116405.3906 - accuracy: 0.3482 - val_loss: 204989.2812 - val_accuracy: 0.3234\n",
      "Epoch 255/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 116505.5000 - accuracy: 0.3468 - val_loss: 126780.4609 - val_accuracy: 0.3234\n",
      "Epoch 256/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 124081.9609 - accuracy: 0.3221 - val_loss: 182407.6250 - val_accuracy: 0.3234\n",
      "Epoch 257/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 129223.4922 - accuracy: 0.3392 - val_loss: 182124.9375 - val_accuracy: 0.3234\n",
      "Epoch 258/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 117136.6172 - accuracy: 0.3482 - val_loss: 162719.8594 - val_accuracy: 0.4213\n",
      "Epoch 259/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 116971.3516 - accuracy: 0.3396 - val_loss: 152557.7500 - val_accuracy: 0.4213\n",
      "Epoch 260/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 122225.5391 - accuracy: 0.3468 - val_loss: 166797.3438 - val_accuracy: 0.3234\n",
      "Epoch 261/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 122278.3828 - accuracy: 0.3306 - val_loss: 119764.4219 - val_accuracy: 0.2936\n",
      "Epoch 262/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 122255.3984 - accuracy: 0.3392 - val_loss: 216270.1562 - val_accuracy: 0.3234\n",
      "Epoch 263/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 126961.3906 - accuracy: 0.3359 - val_loss: 201952.6875 - val_accuracy: 0.3234\n",
      "Epoch 264/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 129461.8125 - accuracy: 0.3198 - val_loss: 151098.5469 - val_accuracy: 0.4213\n",
      "Epoch 265/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 126121.8984 - accuracy: 0.3496 - val_loss: 182080.8125 - val_accuracy: 0.3234\n",
      "Epoch 266/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 116314.6484 - accuracy: 0.3458 - val_loss: 182056.5781 - val_accuracy: 0.3234\n",
      "Epoch 267/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 141853.8906 - accuracy: 0.3240 - val_loss: 123248.4766 - val_accuracy: 0.2936\n",
      "Epoch 268/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 129344.6328 - accuracy: 0.3349 - val_loss: 187163.2344 - val_accuracy: 0.3234\n",
      "Epoch 269/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 128326.7891 - accuracy: 0.3297 - val_loss: 140030.3594 - val_accuracy: 0.3234\n",
      "Epoch 270/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 129679.0078 - accuracy: 0.3292 - val_loss: 189260.2500 - val_accuracy: 0.3234\n",
      "Epoch 271/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 128051.1172 - accuracy: 0.3444 - val_loss: 181035.5781 - val_accuracy: 0.4213\n",
      "Epoch 272/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 147735.1094 - accuracy: 0.3288 - val_loss: 169815.6875 - val_accuracy: 0.3234\n",
      "Epoch 273/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 127375.0391 - accuracy: 0.3373 - val_loss: 138430.6406 - val_accuracy: 0.3234\n",
      "Epoch 274/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 127432.7656 - accuracy: 0.3453 - val_loss: 178328.5156 - val_accuracy: 0.3234\n",
      "Epoch 275/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 146739.1094 - accuracy: 0.3396 - val_loss: 180360.1719 - val_accuracy: 0.2936\n",
      "Epoch 276/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 134039.9844 - accuracy: 0.3378 - val_loss: 198448.4844 - val_accuracy: 0.3234\n",
      "Epoch 277/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 136388.3125 - accuracy: 0.3430 - val_loss: 184777.5312 - val_accuracy: 0.3234\n",
      "Epoch 278/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 132479.2188 - accuracy: 0.3297 - val_loss: 190378.4844 - val_accuracy: 0.3234\n",
      "Epoch 279/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 133594.3750 - accuracy: 0.3581 - val_loss: 171789.6094 - val_accuracy: 0.4213\n",
      "Epoch 280/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 139726.5469 - accuracy: 0.3406 - val_loss: 171797.7812 - val_accuracy: 0.4213\n",
      "Epoch 281/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 139084.6094 - accuracy: 0.3468 - val_loss: 210489.7344 - val_accuracy: 0.4213\n",
      "Epoch 282/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 136809.9062 - accuracy: 0.3534 - val_loss: 279076.5000 - val_accuracy: 0.3234\n",
      "Epoch 283/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 142825.1094 - accuracy: 0.3415 - val_loss: 187470.4375 - val_accuracy: 0.3234\n",
      "Epoch 284/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 149330.2812 - accuracy: 0.3330 - val_loss: 214906.5469 - val_accuracy: 0.3234\n",
      "Epoch 285/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 147649.9688 - accuracy: 0.3600 - val_loss: 237721.0625 - val_accuracy: 0.3234\n",
      "Epoch 286/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 143197.3750 - accuracy: 0.3591 - val_loss: 247440.3438 - val_accuracy: 0.3234\n",
      "Epoch 287/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 144650.6406 - accuracy: 0.3382 - val_loss: 235371.8438 - val_accuracy: 0.3234\n",
      "Epoch 288/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 149713.8281 - accuracy: 0.3335 - val_loss: 194840.5156 - val_accuracy: 0.3234\n",
      "Epoch 289/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 145903.2969 - accuracy: 0.3359 - val_loss: 245243.6406 - val_accuracy: 0.3234\n",
      "Epoch 290/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 144783.4844 - accuracy: 0.3373 - val_loss: 217694.2344 - val_accuracy: 0.3234\n",
      "Epoch 291/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 131325.6719 - accuracy: 0.3501 - val_loss: 269792.9688 - val_accuracy: 0.3234\n",
      "Epoch 292/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 146942.7812 - accuracy: 0.3368 - val_loss: 223937.9062 - val_accuracy: 0.4213\n",
      "Epoch 293/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 151981.8750 - accuracy: 0.3382 - val_loss: 245610.2188 - val_accuracy: 0.4213\n",
      "Epoch 294/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 151748.8750 - accuracy: 0.3382 - val_loss: 230822.6719 - val_accuracy: 0.4213\n",
      "Epoch 295/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 164899.2344 - accuracy: 0.3278 - val_loss: 219708.4531 - val_accuracy: 0.4213\n",
      "Epoch 296/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 152741.6250 - accuracy: 0.3468 - val_loss: 228433.1562 - val_accuracy: 0.2936\n",
      "Epoch 297/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 154426.2031 - accuracy: 0.3468 - val_loss: 283271.6250 - val_accuracy: 0.3234\n",
      "Epoch 298/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 155170.7188 - accuracy: 0.3354 - val_loss: 201499.7812 - val_accuracy: 0.2936\n",
      "Epoch 299/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 153972.8750 - accuracy: 0.3382 - val_loss: 256754.3906 - val_accuracy: 0.3234\n",
      "Epoch 300/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 152947.7188 - accuracy: 0.3373 - val_loss: 215110.2656 - val_accuracy: 0.4213\n",
      "Epoch 301/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 152459.2812 - accuracy: 0.3463 - val_loss: 251694.2969 - val_accuracy: 0.3234\n",
      "Epoch 302/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 166848.7656 - accuracy: 0.3411 - val_loss: 301542.9375 - val_accuracy: 0.3234\n",
      "Epoch 303/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 185077.2969 - accuracy: 0.3449 - val_loss: 306265.8750 - val_accuracy: 0.3234\n",
      "Epoch 304/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 168557.8125 - accuracy: 0.3472 - val_loss: 243611.2344 - val_accuracy: 0.3234\n",
      "Epoch 305/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 160835.0625 - accuracy: 0.3458 - val_loss: 286261.3750 - val_accuracy: 0.3234\n",
      "Epoch 306/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 157460.7656 - accuracy: 0.3359 - val_loss: 263529.1250 - val_accuracy: 0.3234\n",
      "Epoch 307/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 162788.4688 - accuracy: 0.3411 - val_loss: 277666.8750 - val_accuracy: 0.3234\n",
      "Epoch 308/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 174514.1406 - accuracy: 0.3269 - val_loss: 346417.0312 - val_accuracy: 0.3234\n",
      "Epoch 309/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 173825.4531 - accuracy: 0.3529 - val_loss: 268995.0000 - val_accuracy: 0.3234\n",
      "Epoch 310/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 168769.1250 - accuracy: 0.3235 - val_loss: 231022.0312 - val_accuracy: 0.3234\n",
      "Epoch 311/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 165575.4219 - accuracy: 0.3501 - val_loss: 276479.4688 - val_accuracy: 0.3234\n",
      "Epoch 312/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 160691.1719 - accuracy: 0.3406 - val_loss: 293347.6875 - val_accuracy: 0.3234\n",
      "Epoch 313/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 163449.9375 - accuracy: 0.3468 - val_loss: 314468.7812 - val_accuracy: 0.3234\n",
      "Epoch 314/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 6ms/step - loss: 163749.8438 - accuracy: 0.3434 - val_loss: 239832.7812 - val_accuracy: 0.2936\n",
      "Epoch 315/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 174925.1875 - accuracy: 0.3330 - val_loss: 333017.3125 - val_accuracy: 0.3234\n",
      "Epoch 316/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 183306.4844 - accuracy: 0.3510 - val_loss: 340164.6250 - val_accuracy: 0.3234\n",
      "Epoch 317/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 170032.4531 - accuracy: 0.3235 - val_loss: 287135.5938 - val_accuracy: 0.3234\n",
      "Epoch 318/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 174479.4688 - accuracy: 0.3330 - val_loss: 319576.2500 - val_accuracy: 0.3234\n",
      "Epoch 319/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 178793.5625 - accuracy: 0.3188 - val_loss: 229765.4531 - val_accuracy: 0.4213\n",
      "Epoch 320/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 192408.2500 - accuracy: 0.3207 - val_loss: 226502.8125 - val_accuracy: 0.3234\n",
      "Epoch 321/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 171612.1719 - accuracy: 0.3392 - val_loss: 274616.0938 - val_accuracy: 0.2936\n",
      "Epoch 322/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 166453.5469 - accuracy: 0.3572 - val_loss: 293603.1250 - val_accuracy: 0.3234\n",
      "Epoch 323/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 170748.5469 - accuracy: 0.3501 - val_loss: 209806.7031 - val_accuracy: 0.4213\n",
      "Epoch 324/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 176798.8594 - accuracy: 0.3468 - val_loss: 201431.6875 - val_accuracy: 0.4213\n",
      "Epoch 325/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 168504.5156 - accuracy: 0.3491 - val_loss: 206726.5312 - val_accuracy: 0.3234\n",
      "Epoch 326/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 175330.4688 - accuracy: 0.3354 - val_loss: 209565.4062 - val_accuracy: 0.3234\n",
      "Epoch 327/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 178500.3906 - accuracy: 0.3354 - val_loss: 268055.4062 - val_accuracy: 0.3234\n",
      "Epoch 328/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 177413.7031 - accuracy: 0.3434 - val_loss: 267681.2188 - val_accuracy: 0.3234\n",
      "Epoch 329/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 180002.9844 - accuracy: 0.3335 - val_loss: 201880.5156 - val_accuracy: 0.3234\n",
      "Epoch 330/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 185593.6875 - accuracy: 0.3501 - val_loss: 288199.3438 - val_accuracy: 0.4213\n",
      "Epoch 331/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 181886.7812 - accuracy: 0.3415 - val_loss: 226464.6875 - val_accuracy: 0.3234\n",
      "Epoch 332/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 178176.7344 - accuracy: 0.3567 - val_loss: 180317.6875 - val_accuracy: 0.4213\n",
      "Epoch 333/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 168573.2656 - accuracy: 0.3605 - val_loss: 275540.4375 - val_accuracy: 0.3234\n",
      "Epoch 334/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 183464.9844 - accuracy: 0.3415 - val_loss: 243282.7969 - val_accuracy: 0.3234\n",
      "Epoch 335/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 192695.5469 - accuracy: 0.3406 - val_loss: 214865.1562 - val_accuracy: 0.2936\n",
      "Epoch 336/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 195774.3281 - accuracy: 0.3401 - val_loss: 245131.4375 - val_accuracy: 0.3234\n",
      "Epoch 337/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 176363.7500 - accuracy: 0.3449 - val_loss: 300267.8438 - val_accuracy: 0.3234\n",
      "Epoch 338/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 177965.5312 - accuracy: 0.3572 - val_loss: 226798.5625 - val_accuracy: 0.4213\n",
      "Epoch 339/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 186805.8438 - accuracy: 0.3477 - val_loss: 187555.9531 - val_accuracy: 0.3234\n",
      "Epoch 340/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 187653.7656 - accuracy: 0.3406 - val_loss: 244073.1250 - val_accuracy: 0.4213\n",
      "Epoch 341/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 188755.1875 - accuracy: 0.3354 - val_loss: 239157.3750 - val_accuracy: 0.4213\n",
      "Epoch 342/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 185090.3594 - accuracy: 0.3458 - val_loss: 223634.5156 - val_accuracy: 0.4213\n",
      "Epoch 343/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 184986.5625 - accuracy: 0.3468 - val_loss: 232893.5469 - val_accuracy: 0.4213\n",
      "Epoch 344/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 193257.5000 - accuracy: 0.3288 - val_loss: 281601.6250 - val_accuracy: 0.3234\n",
      "Epoch 345/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 204859.6094 - accuracy: 0.3202 - val_loss: 224460.2500 - val_accuracy: 0.4213\n",
      "Epoch 346/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 195318.3594 - accuracy: 0.3330 - val_loss: 266744.3750 - val_accuracy: 0.4213\n",
      "Epoch 347/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 196861.3906 - accuracy: 0.3411 - val_loss: 222893.2031 - val_accuracy: 0.4213\n",
      "Epoch 348/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 192257.3906 - accuracy: 0.3425 - val_loss: 203256.3750 - val_accuracy: 0.3234\n",
      "Epoch 349/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 200078.1875 - accuracy: 0.3378 - val_loss: 293438.6250 - val_accuracy: 0.3234\n",
      "Epoch 350/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 195650.8125 - accuracy: 0.3482 - val_loss: 239210.2188 - val_accuracy: 0.3234\n",
      "Epoch 351/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 206047.2031 - accuracy: 0.3340 - val_loss: 201989.9844 - val_accuracy: 0.4213\n",
      "Epoch 352/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 202070.0469 - accuracy: 0.3667 - val_loss: 199420.7344 - val_accuracy: 0.3234\n",
      "Epoch 353/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 221141.7344 - accuracy: 0.3420 - val_loss: 306477.7500 - val_accuracy: 0.3234\n",
      "Epoch 354/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 217789.7188 - accuracy: 0.3486 - val_loss: 252669.8281 - val_accuracy: 0.3234\n",
      "Epoch 355/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 216316.3594 - accuracy: 0.3548 - val_loss: 264497.0312 - val_accuracy: 0.4213\n",
      "Epoch 356/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 202770.1250 - accuracy: 0.3501 - val_loss: 199344.4844 - val_accuracy: 0.4213\n",
      "Epoch 357/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 213090.3438 - accuracy: 0.3311 - val_loss: 239168.2656 - val_accuracy: 0.4213\n",
      "Epoch 358/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 215721.2344 - accuracy: 0.3269 - val_loss: 186491.0938 - val_accuracy: 0.4213\n",
      "Epoch 359/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 194910.9531 - accuracy: 0.3719 - val_loss: 310716.4688 - val_accuracy: 0.4213\n",
      "Epoch 360/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 214355.3750 - accuracy: 0.3515 - val_loss: 330079.8750 - val_accuracy: 0.4213\n",
      "Epoch 361/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 214861.7969 - accuracy: 0.3411 - val_loss: 234197.5156 - val_accuracy: 0.2936\n",
      "Epoch 362/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 227804.2812 - accuracy: 0.3354 - val_loss: 394648.5000 - val_accuracy: 0.3234\n",
      "Epoch 363/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 224491.6250 - accuracy: 0.3434 - val_loss: 205718.3281 - val_accuracy: 0.4213\n",
      "Epoch 364/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 216066.9062 - accuracy: 0.3477 - val_loss: 393275.9062 - val_accuracy: 0.3234\n",
      "Epoch 365/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 220653.9375 - accuracy: 0.3610 - val_loss: 294681.0625 - val_accuracy: 0.3234\n",
      "Epoch 366/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 213259.2812 - accuracy: 0.3515 - val_loss: 328951.2812 - val_accuracy: 0.3234\n",
      "Epoch 367/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 220398.5938 - accuracy: 0.3226 - val_loss: 240355.6719 - val_accuracy: 0.4213\n",
      "Epoch 368/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 207903.4062 - accuracy: 0.3775 - val_loss: 204773.8594 - val_accuracy: 0.2936\n",
      "Epoch 369/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 230525.3281 - accuracy: 0.3496 - val_loss: 285596.8750 - val_accuracy: 0.3234\n",
      "Epoch 370/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 231849.7812 - accuracy: 0.3482 - val_loss: 227525.1719 - val_accuracy: 0.2936\n",
      "Epoch 371/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 217414.1562 - accuracy: 0.3449 - val_loss: 236259.6719 - val_accuracy: 0.3234\n",
      "Epoch 372/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 211137.3594 - accuracy: 0.3425 - val_loss: 253311.4531 - val_accuracy: 0.3234\n",
      "Epoch 373/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 221305.6406 - accuracy: 0.3231 - val_loss: 283571.7500 - val_accuracy: 0.4213\n",
      "Epoch 374/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 228174.2188 - accuracy: 0.3297 - val_loss: 297761.7812 - val_accuracy: 0.3234\n",
      "Epoch 375/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 235989.1875 - accuracy: 0.3401 - val_loss: 223235.2656 - val_accuracy: 0.4213\n",
      "Epoch 376/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 230414.5469 - accuracy: 0.3321 - val_loss: 391579.7812 - val_accuracy: 0.3234\n",
      "Epoch 377/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 236672.7344 - accuracy: 0.3453 - val_loss: 250248.1719 - val_accuracy: 0.4213\n",
      "Epoch 378/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 228234.0000 - accuracy: 0.3510 - val_loss: 348386.5938 - val_accuracy: 0.3234\n",
      "Epoch 379/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 235553.1094 - accuracy: 0.3316 - val_loss: 316373.5000 - val_accuracy: 0.4213\n",
      "Epoch 380/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 216271.8594 - accuracy: 0.3420 - val_loss: 329561.3125 - val_accuracy: 0.3234\n",
      "Epoch 381/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 233842.6562 - accuracy: 0.3629 - val_loss: 364570.1562 - val_accuracy: 0.3234\n",
      "Epoch 382/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 236255.7969 - accuracy: 0.3401 - val_loss: 341821.0000 - val_accuracy: 0.3234\n",
      "Epoch 383/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 220654.5312 - accuracy: 0.3482 - val_loss: 437858.0312 - val_accuracy: 0.3234\n",
      "Epoch 384/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 270649.3125 - accuracy: 0.3382 - val_loss: 368069.1875 - val_accuracy: 0.3234\n",
      "Epoch 385/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 238193.0156 - accuracy: 0.3572 - val_loss: 328926.2188 - val_accuracy: 0.3234\n",
      "Epoch 386/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 254418.7031 - accuracy: 0.3472 - val_loss: 342378.7500 - val_accuracy: 0.3234\n",
      "Epoch 387/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 237013.1875 - accuracy: 0.3363 - val_loss: 356812.8125 - val_accuracy: 0.4213\n",
      "Epoch 388/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 246101.9844 - accuracy: 0.3373 - val_loss: 304843.7188 - val_accuracy: 0.3234\n",
      "Epoch 389/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 237599.5938 - accuracy: 0.3624 - val_loss: 495313.1562 - val_accuracy: 0.3234\n",
      "Epoch 390/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 241179.4688 - accuracy: 0.3453 - val_loss: 303328.4062 - val_accuracy: 0.4213\n",
      "Epoch 391/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 239366.3125 - accuracy: 0.3420 - val_loss: 400088.7812 - val_accuracy: 0.3234\n",
      "Epoch 392/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 257540.0625 - accuracy: 0.3396 - val_loss: 321112.2500 - val_accuracy: 0.2936\n",
      "Epoch 393/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 257257.9219 - accuracy: 0.3231 - val_loss: 382301.6875 - val_accuracy: 0.3234\n",
      "Epoch 394/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 250120.0625 - accuracy: 0.3387 - val_loss: 547077.4375 - val_accuracy: 0.3234\n",
      "Epoch 395/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 249498.5625 - accuracy: 0.3534 - val_loss: 314023.7500 - val_accuracy: 0.4213\n",
      "Epoch 396/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 273980.5625 - accuracy: 0.3406 - val_loss: 300704.1250 - val_accuracy: 0.4213\n",
      "Epoch 397/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 258617.6562 - accuracy: 0.3505 - val_loss: 296324.9062 - val_accuracy: 0.3234\n",
      "Epoch 398/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 275405.1250 - accuracy: 0.3515 - val_loss: 298062.4375 - val_accuracy: 0.3234\n",
      "Epoch 399/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 256801.2344 - accuracy: 0.3396 - val_loss: 376943.1250 - val_accuracy: 0.3234\n",
      "Epoch 400/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 265828.9062 - accuracy: 0.3420 - val_loss: 334727.0938 - val_accuracy: 0.2936\n",
      "Epoch 401/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 251956.7500 - accuracy: 0.3558 - val_loss: 383971.6875 - val_accuracy: 0.3234\n",
      "Epoch 402/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 262851.9688 - accuracy: 0.3449 - val_loss: 426282.5000 - val_accuracy: 0.4213\n",
      "Epoch 403/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 252065.4062 - accuracy: 0.3695 - val_loss: 381127.3438 - val_accuracy: 0.3234\n",
      "Epoch 404/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 256595.9219 - accuracy: 0.3378 - val_loss: 436435.3438 - val_accuracy: 0.3234\n",
      "Epoch 405/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 254760.3750 - accuracy: 0.3553 - val_loss: 437690.2812 - val_accuracy: 0.3234\n",
      "Epoch 406/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 261430.5781 - accuracy: 0.3491 - val_loss: 341428.8438 - val_accuracy: 0.2936\n",
      "Epoch 407/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 258205.2812 - accuracy: 0.3534 - val_loss: 376601.0625 - val_accuracy: 0.3234\n",
      "Epoch 408/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 262024.7969 - accuracy: 0.3378 - val_loss: 418064.3438 - val_accuracy: 0.4213\n",
      "Epoch 409/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 271702.0938 - accuracy: 0.3363 - val_loss: 480781.0625 - val_accuracy: 0.4213\n",
      "Epoch 410/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 279242.4062 - accuracy: 0.3321 - val_loss: 377350.5312 - val_accuracy: 0.4213\n",
      "Epoch 411/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 263792.6562 - accuracy: 0.3411 - val_loss: 436737.0938 - val_accuracy: 0.4213\n",
      "Epoch 412/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 271762.6250 - accuracy: 0.3472 - val_loss: 497511.5000 - val_accuracy: 0.3234\n",
      "Epoch 413/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 274372.2188 - accuracy: 0.3368 - val_loss: 368633.4688 - val_accuracy: 0.4213\n",
      "Epoch 414/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 278795.0312 - accuracy: 0.3425 - val_loss: 545112.2500 - val_accuracy: 0.3234\n",
      "Epoch 415/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 268513.5625 - accuracy: 0.3439 - val_loss: 438414.7188 - val_accuracy: 0.3234\n",
      "Epoch 416/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 263444.8438 - accuracy: 0.3581 - val_loss: 462465.6250 - val_accuracy: 0.4213\n",
      "Epoch 417/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 287338.1250 - accuracy: 0.3254 - val_loss: 448206.9688 - val_accuracy: 0.3234\n",
      "Epoch 418/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 275283.3125 - accuracy: 0.3449 - val_loss: 433635.6875 - val_accuracy: 0.4213\n",
      "Epoch 419/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 291414.9375 - accuracy: 0.3283 - val_loss: 442447.5312 - val_accuracy: 0.4213\n",
      "Epoch 420/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 6ms/step - loss: 288941.9062 - accuracy: 0.3439 - val_loss: 646963.1875 - val_accuracy: 0.3234\n",
      "Epoch 421/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 279968.9375 - accuracy: 0.3524 - val_loss: 456604.8750 - val_accuracy: 0.2936\n",
      "Epoch 422/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 271652.1250 - accuracy: 0.3420 - val_loss: 610750.6250 - val_accuracy: 0.3234\n",
      "Epoch 423/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 277517.3438 - accuracy: 0.3449 - val_loss: 471723.0312 - val_accuracy: 0.3234\n",
      "Epoch 424/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 292329.9375 - accuracy: 0.3434 - val_loss: 456529.6875 - val_accuracy: 0.3234\n",
      "Epoch 425/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 274223.7812 - accuracy: 0.3430 - val_loss: 380439.9688 - val_accuracy: 0.3234\n",
      "Epoch 426/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 296605.2812 - accuracy: 0.3302 - val_loss: 566396.1875 - val_accuracy: 0.3234\n",
      "Epoch 427/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 286603.2188 - accuracy: 0.3515 - val_loss: 457326.0312 - val_accuracy: 0.3234\n",
      "Epoch 428/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 317669.1875 - accuracy: 0.3430 - val_loss: 363050.5000 - val_accuracy: 0.4213\n",
      "Epoch 429/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 302397.3750 - accuracy: 0.3430 - val_loss: 558647.5625 - val_accuracy: 0.3234\n",
      "Epoch 430/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 301636.5312 - accuracy: 0.3406 - val_loss: 423085.2188 - val_accuracy: 0.3234\n",
      "Epoch 431/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 289465.5312 - accuracy: 0.3472 - val_loss: 495144.3125 - val_accuracy: 0.4213\n",
      "Epoch 432/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 302799.0000 - accuracy: 0.3231 - val_loss: 457875.0625 - val_accuracy: 0.3234\n",
      "Epoch 433/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 296621.0625 - accuracy: 0.3577 - val_loss: 502965.9375 - val_accuracy: 0.4213\n",
      "Epoch 434/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 299348.0312 - accuracy: 0.3278 - val_loss: 433159.6250 - val_accuracy: 0.3234\n",
      "Epoch 435/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 307503.1875 - accuracy: 0.3463 - val_loss: 528105.1250 - val_accuracy: 0.3234\n",
      "Epoch 436/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 301722.8750 - accuracy: 0.3273 - val_loss: 460143.1250 - val_accuracy: 0.4213\n",
      "Epoch 437/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 295261.5000 - accuracy: 0.3572 - val_loss: 473595.6562 - val_accuracy: 0.4213\n",
      "Epoch 438/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 285399.7500 - accuracy: 0.3325 - val_loss: 591463.5000 - val_accuracy: 0.3234\n",
      "Epoch 439/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 317206.4375 - accuracy: 0.3434 - val_loss: 632290.5625 - val_accuracy: 0.3234\n",
      "Epoch 440/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 317734.5625 - accuracy: 0.3486 - val_loss: 557050.5625 - val_accuracy: 0.3234\n",
      "Epoch 441/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 286267.7812 - accuracy: 0.3430 - val_loss: 470884.2188 - val_accuracy: 0.4213\n",
      "Epoch 442/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 289965.1875 - accuracy: 0.3373 - val_loss: 561561.6250 - val_accuracy: 0.3234\n",
      "Epoch 443/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 281727.3438 - accuracy: 0.3486 - val_loss: 428637.6875 - val_accuracy: 0.4213\n",
      "Epoch 444/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 290916.4062 - accuracy: 0.3363 - val_loss: 470998.5938 - val_accuracy: 0.4213\n",
      "Epoch 445/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 325906.0625 - accuracy: 0.3392 - val_loss: 424286.7812 - val_accuracy: 0.4213\n",
      "Epoch 446/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 297575.1875 - accuracy: 0.3553 - val_loss: 551458.8750 - val_accuracy: 0.3234\n",
      "Epoch 447/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 311421.8750 - accuracy: 0.3477 - val_loss: 682515.6250 - val_accuracy: 0.3234\n",
      "Epoch 448/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 314536.9375 - accuracy: 0.3311 - val_loss: 514124.2500 - val_accuracy: 0.3234\n",
      "Epoch 449/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 318278.0938 - accuracy: 0.3439 - val_loss: 590031.0000 - val_accuracy: 0.4213\n",
      "Epoch 450/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 309403.5938 - accuracy: 0.3415 - val_loss: 616471.9375 - val_accuracy: 0.4213\n",
      "Epoch 451/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 313422.3438 - accuracy: 0.3491 - val_loss: 599323.2500 - val_accuracy: 0.3234\n",
      "Epoch 452/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 308377.6562 - accuracy: 0.3472 - val_loss: 497299.0625 - val_accuracy: 0.4213\n",
      "Epoch 453/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 307176.7188 - accuracy: 0.3401 - val_loss: 595552.9375 - val_accuracy: 0.3234\n",
      "Epoch 454/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 324678.4688 - accuracy: 0.3520 - val_loss: 528453.7500 - val_accuracy: 0.3234\n",
      "Epoch 455/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 319691.0000 - accuracy: 0.3392 - val_loss: 562477.7500 - val_accuracy: 0.4213\n",
      "Epoch 456/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 318016.7500 - accuracy: 0.3392 - val_loss: 556431.8125 - val_accuracy: 0.3234\n",
      "Epoch 457/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 332849.9688 - accuracy: 0.3482 - val_loss: 547487.0625 - val_accuracy: 0.4213\n",
      "Epoch 458/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 319066.0938 - accuracy: 0.3505 - val_loss: 482755.0000 - val_accuracy: 0.4213\n",
      "Epoch 459/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 312344.0000 - accuracy: 0.3482 - val_loss: 675114.5000 - val_accuracy: 0.3234\n",
      "Epoch 460/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 344405.7500 - accuracy: 0.3430 - val_loss: 743861.9375 - val_accuracy: 0.4213\n",
      "Epoch 461/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 374380.9062 - accuracy: 0.3387 - val_loss: 508363.7188 - val_accuracy: 0.3234\n",
      "Epoch 462/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 320425.5312 - accuracy: 0.3486 - val_loss: 613430.4375 - val_accuracy: 0.4213\n",
      "Epoch 463/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 335877.2188 - accuracy: 0.3368 - val_loss: 723708.7500 - val_accuracy: 0.3234\n",
      "Epoch 464/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 328210.1875 - accuracy: 0.3344 - val_loss: 578634.0625 - val_accuracy: 0.4213\n",
      "Epoch 465/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 363400.4375 - accuracy: 0.3439 - val_loss: 590168.2500 - val_accuracy: 0.4213\n",
      "Epoch 466/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 342977.9062 - accuracy: 0.3278 - val_loss: 729804.8125 - val_accuracy: 0.3234\n",
      "Epoch 467/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 305333.7812 - accuracy: 0.3359 - val_loss: 599850.5000 - val_accuracy: 0.3234\n",
      "Epoch 468/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 329350.5938 - accuracy: 0.3539 - val_loss: 515631.9375 - val_accuracy: 0.4213\n",
      "Epoch 469/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 306238.9375 - accuracy: 0.3477 - val_loss: 535120.6250 - val_accuracy: 0.3234\n",
      "Epoch 470/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 337680.5000 - accuracy: 0.3406 - val_loss: 602619.6250 - val_accuracy: 0.3234\n",
      "Epoch 471/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 332791.0312 - accuracy: 0.3595 - val_loss: 591621.4375 - val_accuracy: 0.3234\n",
      "Epoch 472/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 310905.0312 - accuracy: 0.3491 - val_loss: 544765.8125 - val_accuracy: 0.3234\n",
      "Epoch 473/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 346438.8125 - accuracy: 0.3553 - val_loss: 534334.0625 - val_accuracy: 0.3234\n",
      "Epoch 474/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 353041.8125 - accuracy: 0.3387 - val_loss: 495968.9688 - val_accuracy: 0.2936\n",
      "Epoch 475/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 342814.9375 - accuracy: 0.3491 - val_loss: 509318.0000 - val_accuracy: 0.2936\n",
      "Epoch 476/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 349098.1562 - accuracy: 0.3259 - val_loss: 539432.3125 - val_accuracy: 0.4213\n",
      "Epoch 477/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 349541.5000 - accuracy: 0.3477 - val_loss: 765699.2500 - val_accuracy: 0.3234\n",
      "Epoch 478/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 351891.4688 - accuracy: 0.3548 - val_loss: 517198.4375 - val_accuracy: 0.3234\n",
      "Epoch 479/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 349803.3125 - accuracy: 0.3325 - val_loss: 542057.6875 - val_accuracy: 0.3234\n",
      "Epoch 480/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 349570.3750 - accuracy: 0.3434 - val_loss: 811966.6250 - val_accuracy: 0.3234\n",
      "Epoch 481/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 358178.9375 - accuracy: 0.3496 - val_loss: 600477.9375 - val_accuracy: 0.3234\n",
      "Epoch 482/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 350261.9688 - accuracy: 0.3306 - val_loss: 534456.1250 - val_accuracy: 0.4213\n",
      "Epoch 483/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 356473.0312 - accuracy: 0.3349 - val_loss: 686605.0625 - val_accuracy: 0.4213\n",
      "Epoch 484/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 376562.5312 - accuracy: 0.3406 - val_loss: 573769.0000 - val_accuracy: 0.4213\n",
      "Epoch 485/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 346424.2812 - accuracy: 0.3515 - val_loss: 688021.2500 - val_accuracy: 0.3234\n",
      "Epoch 486/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 353107.0625 - accuracy: 0.3368 - val_loss: 594789.3125 - val_accuracy: 0.4213\n",
      "Epoch 487/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 385144.4062 - accuracy: 0.3269 - val_loss: 541815.8125 - val_accuracy: 0.2936\n",
      "Epoch 488/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 355391.6562 - accuracy: 0.3316 - val_loss: 477371.3750 - val_accuracy: 0.4213\n",
      "Epoch 489/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 364511.6250 - accuracy: 0.3264 - val_loss: 729539.0000 - val_accuracy: 0.3234\n",
      "Epoch 490/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 382323.2188 - accuracy: 0.3349 - val_loss: 632692.5625 - val_accuracy: 0.3234\n",
      "Epoch 491/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 367303.9688 - accuracy: 0.3179 - val_loss: 701047.8125 - val_accuracy: 0.3234\n",
      "Epoch 492/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 360575.5625 - accuracy: 0.3524 - val_loss: 571052.1250 - val_accuracy: 0.4213\n",
      "Epoch 493/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 376447.0938 - accuracy: 0.3486 - val_loss: 699583.7500 - val_accuracy: 0.3234\n",
      "Epoch 494/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 357229.7500 - accuracy: 0.3392 - val_loss: 694644.5625 - val_accuracy: 0.4213\n",
      "Epoch 495/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 367829.8125 - accuracy: 0.3468 - val_loss: 730852.7500 - val_accuracy: 0.3234\n",
      "Epoch 496/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 350844.0625 - accuracy: 0.3382 - val_loss: 750463.4375 - val_accuracy: 0.3234\n",
      "Epoch 497/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 354308.3750 - accuracy: 0.3420 - val_loss: 670343.0625 - val_accuracy: 0.3234\n",
      "Epoch 498/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 358793.2812 - accuracy: 0.3468 - val_loss: 559215.1250 - val_accuracy: 0.3234\n",
      "Epoch 499/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 349088.4375 - accuracy: 0.3468 - val_loss: 690995.1875 - val_accuracy: 0.3234\n",
      "Epoch 500/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 365669.5000 - accuracy: 0.3468 - val_loss: 793401.7500 - val_accuracy: 0.3234\n",
      "Epoch 501/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 379651.1562 - accuracy: 0.3477 - val_loss: 557759.7500 - val_accuracy: 0.4213\n",
      "Epoch 502/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 381997.0000 - accuracy: 0.3382 - val_loss: 589797.8750 - val_accuracy: 0.4213\n",
      "Epoch 503/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 355073.8125 - accuracy: 0.3311 - val_loss: 592333.8750 - val_accuracy: 0.3234\n",
      "Epoch 504/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 339633.6562 - accuracy: 0.3453 - val_loss: 791081.3750 - val_accuracy: 0.4213\n",
      "Epoch 505/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 375333.9688 - accuracy: 0.3458 - val_loss: 603360.4375 - val_accuracy: 0.3234\n",
      "Epoch 506/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 382830.8438 - accuracy: 0.3415 - val_loss: 749127.8750 - val_accuracy: 0.3234\n",
      "Epoch 507/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 402687.6250 - accuracy: 0.3406 - val_loss: 582555.7500 - val_accuracy: 0.4213\n",
      "Epoch 508/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 409661.2500 - accuracy: 0.3401 - val_loss: 620345.7500 - val_accuracy: 0.2936\n",
      "Epoch 509/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 391871.7188 - accuracy: 0.3335 - val_loss: 619528.6875 - val_accuracy: 0.4213\n",
      "Epoch 510/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 413396.9375 - accuracy: 0.3463 - val_loss: 621886.0625 - val_accuracy: 0.4213\n",
      "Epoch 511/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 415412.9375 - accuracy: 0.3359 - val_loss: 774017.6250 - val_accuracy: 0.3234\n",
      "Epoch 512/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 418343.7812 - accuracy: 0.3453 - val_loss: 639570.8125 - val_accuracy: 0.2936\n",
      "Epoch 513/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 379489.3750 - accuracy: 0.3439 - val_loss: 743624.4375 - val_accuracy: 0.3234\n",
      "Epoch 514/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 405431.5938 - accuracy: 0.3420 - val_loss: 665848.3750 - val_accuracy: 0.4213\n",
      "Epoch 515/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 376935.9375 - accuracy: 0.3411 - val_loss: 635402.8750 - val_accuracy: 0.3234\n",
      "Epoch 516/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 393723.8750 - accuracy: 0.3430 - val_loss: 822864.6250 - val_accuracy: 0.4213\n",
      "Epoch 517/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 377620.7500 - accuracy: 0.3453 - val_loss: 746199.6875 - val_accuracy: 0.3234\n",
      "Epoch 518/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 388570.1562 - accuracy: 0.3425 - val_loss: 598532.3750 - val_accuracy: 0.4213\n",
      "Epoch 519/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 377255.0000 - accuracy: 0.3430 - val_loss: 662955.0000 - val_accuracy: 0.4213\n",
      "Epoch 520/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 385676.1875 - accuracy: 0.3292 - val_loss: 565324.2500 - val_accuracy: 0.3234\n",
      "Epoch 521/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 381654.4062 - accuracy: 0.3491 - val_loss: 493119.1875 - val_accuracy: 0.3234\n",
      "Epoch 522/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 382154.0312 - accuracy: 0.3325 - val_loss: 542846.3750 - val_accuracy: 0.2936\n",
      "Epoch 523/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 382354.3750 - accuracy: 0.3344 - val_loss: 737868.2500 - val_accuracy: 0.3234\n",
      "Epoch 524/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 391110.0312 - accuracy: 0.3401 - val_loss: 774063.3750 - val_accuracy: 0.3234\n",
      "Epoch 525/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 390363.5000 - accuracy: 0.3269 - val_loss: 683472.0625 - val_accuracy: 0.3234\n",
      "Epoch 526/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 6ms/step - loss: 393286.3438 - accuracy: 0.3378 - val_loss: 590050.5625 - val_accuracy: 0.4213\n",
      "Epoch 527/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 380681.0938 - accuracy: 0.3534 - val_loss: 624134.5625 - val_accuracy: 0.4213\n",
      "Epoch 528/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 411905.3438 - accuracy: 0.3245 - val_loss: 683955.7500 - val_accuracy: 0.3234\n",
      "Epoch 529/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 391588.8125 - accuracy: 0.3472 - val_loss: 578499.0000 - val_accuracy: 0.4213\n",
      "Epoch 530/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 409986.3750 - accuracy: 0.3415 - val_loss: 723318.7500 - val_accuracy: 0.2936\n",
      "Epoch 531/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 403857.1562 - accuracy: 0.3619 - val_loss: 842682.2500 - val_accuracy: 0.3234\n",
      "Epoch 532/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 415716.5938 - accuracy: 0.3378 - val_loss: 599125.0000 - val_accuracy: 0.2936\n",
      "Epoch 533/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 389723.1875 - accuracy: 0.3539 - val_loss: 599477.9375 - val_accuracy: 0.3234\n",
      "Epoch 534/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 418071.4062 - accuracy: 0.3567 - val_loss: 682021.0625 - val_accuracy: 0.4213\n",
      "Epoch 535/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 416603.3125 - accuracy: 0.3288 - val_loss: 650841.3125 - val_accuracy: 0.3234\n",
      "Epoch 536/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 413556.7812 - accuracy: 0.3340 - val_loss: 575714.5625 - val_accuracy: 0.3234\n",
      "Epoch 537/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 399583.6250 - accuracy: 0.3558 - val_loss: 598362.4375 - val_accuracy: 0.2936\n",
      "Epoch 538/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 409874.5625 - accuracy: 0.3453 - val_loss: 597761.0625 - val_accuracy: 0.3234\n",
      "Epoch 539/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 415482.0625 - accuracy: 0.3330 - val_loss: 865911.8125 - val_accuracy: 0.3234\n",
      "Epoch 540/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 440800.9688 - accuracy: 0.3439 - val_loss: 434844.8750 - val_accuracy: 0.4213\n",
      "Epoch 541/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 414531.0625 - accuracy: 0.3510 - val_loss: 761078.1875 - val_accuracy: 0.3234\n",
      "Epoch 542/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 404638.6250 - accuracy: 0.3264 - val_loss: 476316.8750 - val_accuracy: 0.3234\n",
      "Epoch 543/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 424460.1250 - accuracy: 0.3235 - val_loss: 583429.4375 - val_accuracy: 0.3234\n",
      "Epoch 544/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 413095.0000 - accuracy: 0.3434 - val_loss: 650516.6875 - val_accuracy: 0.3234\n",
      "Epoch 545/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 438023.6250 - accuracy: 0.3534 - val_loss: 683646.3750 - val_accuracy: 0.3234\n",
      "Epoch 546/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 420223.6875 - accuracy: 0.3515 - val_loss: 635439.9375 - val_accuracy: 0.3234\n",
      "Epoch 547/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 442734.2188 - accuracy: 0.3539 - val_loss: 436620.5312 - val_accuracy: 0.4213\n",
      "Epoch 548/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 403219.2812 - accuracy: 0.3600 - val_loss: 548715.8750 - val_accuracy: 0.4213\n",
      "Epoch 549/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 433112.9375 - accuracy: 0.3278 - val_loss: 652959.0625 - val_accuracy: 0.4213\n",
      "Epoch 550/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 469284.7500 - accuracy: 0.3311 - val_loss: 686761.9375 - val_accuracy: 0.3234\n",
      "Epoch 551/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 421009.5312 - accuracy: 0.3600 - val_loss: 587277.0625 - val_accuracy: 0.3234\n",
      "Epoch 552/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 437258.9062 - accuracy: 0.3444 - val_loss: 613047.0000 - val_accuracy: 0.4213\n",
      "Epoch 553/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 452757.1562 - accuracy: 0.3269 - val_loss: 633666.4375 - val_accuracy: 0.3234\n",
      "Epoch 554/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 434393.0625 - accuracy: 0.3288 - val_loss: 552487.1875 - val_accuracy: 0.3234\n",
      "Epoch 555/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 445416.7188 - accuracy: 0.3468 - val_loss: 583022.0000 - val_accuracy: 0.4213\n",
      "Epoch 556/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 441692.0312 - accuracy: 0.3430 - val_loss: 598334.0625 - val_accuracy: 0.3234\n",
      "Epoch 557/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 525860.3750 - accuracy: 0.3553 - val_loss: 572087.0000 - val_accuracy: 0.4213\n",
      "Epoch 558/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 444562.5000 - accuracy: 0.3510 - val_loss: 544120.9375 - val_accuracy: 0.4213\n",
      "Epoch 559/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 432186.2188 - accuracy: 0.3415 - val_loss: 696618.5000 - val_accuracy: 0.3234\n",
      "Epoch 560/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 444977.9688 - accuracy: 0.3406 - val_loss: 624372.0000 - val_accuracy: 0.4213\n",
      "Epoch 561/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 432466.8125 - accuracy: 0.3738 - val_loss: 1040024.5000 - val_accuracy: 0.3234\n",
      "Epoch 562/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 459892.1875 - accuracy: 0.3425 - val_loss: 862059.8750 - val_accuracy: 0.3234\n",
      "Epoch 563/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 493328.1250 - accuracy: 0.3401 - val_loss: 571335.3750 - val_accuracy: 0.3234\n",
      "Epoch 564/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 452741.4062 - accuracy: 0.3330 - val_loss: 772337.8125 - val_accuracy: 0.3234\n",
      "Epoch 565/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 451442.3438 - accuracy: 0.3430 - val_loss: 623711.8750 - val_accuracy: 0.3234\n",
      "Epoch 566/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 445481.9688 - accuracy: 0.3501 - val_loss: 816258.7500 - val_accuracy: 0.3234\n",
      "Epoch 567/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 440669.2500 - accuracy: 0.3520 - val_loss: 667088.0625 - val_accuracy: 0.4213\n",
      "Epoch 568/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 484342.5312 - accuracy: 0.3595 - val_loss: 722832.8750 - val_accuracy: 0.3234\n",
      "Epoch 569/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 452452.5312 - accuracy: 0.3486 - val_loss: 769043.6250 - val_accuracy: 0.4213\n",
      "Epoch 570/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 458929.2812 - accuracy: 0.3363 - val_loss: 600432.1875 - val_accuracy: 0.4213\n",
      "Epoch 571/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 460460.6875 - accuracy: 0.3382 - val_loss: 696352.6875 - val_accuracy: 0.4213\n",
      "Epoch 572/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 472169.0312 - accuracy: 0.3269 - val_loss: 613445.7500 - val_accuracy: 0.4213\n",
      "Epoch 573/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 463283.1250 - accuracy: 0.3439 - val_loss: 724826.4375 - val_accuracy: 0.4213\n",
      "Epoch 574/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 471435.5938 - accuracy: 0.3302 - val_loss: 639309.3750 - val_accuracy: 0.3234\n",
      "Epoch 575/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 510591.0938 - accuracy: 0.3373 - val_loss: 771738.6875 - val_accuracy: 0.2936\n",
      "Epoch 576/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 470696.8125 - accuracy: 0.3359 - val_loss: 734761.3750 - val_accuracy: 0.3234\n",
      "Epoch 577/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 455191.2812 - accuracy: 0.3477 - val_loss: 767311.5000 - val_accuracy: 0.4213\n",
      "Epoch 578/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 483599.6562 - accuracy: 0.3330 - val_loss: 826607.6875 - val_accuracy: 0.4213\n",
      "Epoch 579/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 484049.0625 - accuracy: 0.3453 - val_loss: 926650.2500 - val_accuracy: 0.3234\n",
      "Epoch 580/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 462014.1562 - accuracy: 0.3505 - val_loss: 729308.0625 - val_accuracy: 0.3234\n",
      "Epoch 581/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 487757.0000 - accuracy: 0.3264 - val_loss: 897409.6250 - val_accuracy: 0.4213\n",
      "Epoch 582/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 495985.6250 - accuracy: 0.3297 - val_loss: 920421.3125 - val_accuracy: 0.4213\n",
      "Epoch 583/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 486397.5625 - accuracy: 0.3425 - val_loss: 606144.8125 - val_accuracy: 0.4213\n",
      "Epoch 584/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 443931.6562 - accuracy: 0.3610 - val_loss: 865277.8125 - val_accuracy: 0.3234\n",
      "Epoch 585/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 498913.0625 - accuracy: 0.3349 - val_loss: 725896.1875 - val_accuracy: 0.3234\n",
      "Epoch 586/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 476755.9062 - accuracy: 0.3401 - val_loss: 779303.1875 - val_accuracy: 0.4213\n",
      "Epoch 587/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 475669.0938 - accuracy: 0.3406 - val_loss: 805471.8750 - val_accuracy: 0.4213\n",
      "Epoch 588/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 487788.5312 - accuracy: 0.3463 - val_loss: 943191.1250 - val_accuracy: 0.4213\n",
      "Epoch 589/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 487172.5000 - accuracy: 0.3392 - val_loss: 881457.0000 - val_accuracy: 0.3234\n",
      "Epoch 590/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 482058.3125 - accuracy: 0.3567 - val_loss: 789957.1875 - val_accuracy: 0.4213\n",
      "Epoch 591/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 500494.4375 - accuracy: 0.3401 - val_loss: 820515.9375 - val_accuracy: 0.3234\n",
      "Epoch 592/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 476842.7500 - accuracy: 0.3392 - val_loss: 813476.5000 - val_accuracy: 0.3234\n",
      "Epoch 593/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 493969.8750 - accuracy: 0.3340 - val_loss: 876005.8750 - val_accuracy: 0.3234\n",
      "Epoch 594/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 539652.1250 - accuracy: 0.3363 - val_loss: 789015.9375 - val_accuracy: 0.3234\n",
      "Epoch 595/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 519479.1875 - accuracy: 0.3468 - val_loss: 888814.5625 - val_accuracy: 0.3234\n",
      "Epoch 596/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 516139.6562 - accuracy: 0.3472 - val_loss: 746901.2500 - val_accuracy: 0.4213\n",
      "Epoch 597/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 507573.6562 - accuracy: 0.3453 - val_loss: 586494.9375 - val_accuracy: 0.2936\n",
      "Epoch 598/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 537534.7500 - accuracy: 0.3216 - val_loss: 684777.1250 - val_accuracy: 0.4213\n",
      "Epoch 599/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 544304.5000 - accuracy: 0.3378 - val_loss: 615628.8125 - val_accuracy: 0.4213\n",
      "Epoch 600/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 531562.5000 - accuracy: 0.3235 - val_loss: 662802.5000 - val_accuracy: 0.3234\n",
      "Epoch 601/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 526577.8125 - accuracy: 0.3207 - val_loss: 1054890.0000 - val_accuracy: 0.3234\n",
      "Epoch 602/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 539604.1250 - accuracy: 0.3449 - val_loss: 919595.5625 - val_accuracy: 0.3234\n",
      "Epoch 603/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 579661.1250 - accuracy: 0.3415 - val_loss: 876326.1250 - val_accuracy: 0.4213\n",
      "Epoch 604/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 572337.8750 - accuracy: 0.3359 - val_loss: 791364.6250 - val_accuracy: 0.4213\n",
      "Epoch 605/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 523320.2812 - accuracy: 0.3335 - val_loss: 924706.8750 - val_accuracy: 0.3234\n",
      "Epoch 606/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 503612.7500 - accuracy: 0.3330 - val_loss: 864456.4375 - val_accuracy: 0.3234\n",
      "Epoch 607/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 519947.0312 - accuracy: 0.3453 - val_loss: 894779.9375 - val_accuracy: 0.3234\n",
      "Epoch 608/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 514346.0938 - accuracy: 0.3302 - val_loss: 831252.6875 - val_accuracy: 0.3234\n",
      "Epoch 609/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 529497.2500 - accuracy: 0.3472 - val_loss: 895342.0000 - val_accuracy: 0.3234\n",
      "Epoch 610/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 494435.8125 - accuracy: 0.3198 - val_loss: 823034.5625 - val_accuracy: 0.3234\n",
      "Epoch 611/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 521086.7188 - accuracy: 0.3382 - val_loss: 993759.3125 - val_accuracy: 0.3234\n",
      "Epoch 612/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 534372.0625 - accuracy: 0.3335 - val_loss: 794288.5000 - val_accuracy: 0.3234\n",
      "Epoch 613/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 526611.5000 - accuracy: 0.3501 - val_loss: 960115.5000 - val_accuracy: 0.3234\n",
      "Epoch 614/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 580277.6875 - accuracy: 0.3439 - val_loss: 884156.4375 - val_accuracy: 0.4213\n",
      "Epoch 615/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 488692.9688 - accuracy: 0.3567 - val_loss: 990913.9375 - val_accuracy: 0.3234\n",
      "Epoch 616/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 507992.2812 - accuracy: 0.3278 - val_loss: 774043.7500 - val_accuracy: 0.3234\n",
      "Epoch 617/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 494080.5000 - accuracy: 0.3335 - val_loss: 908466.6250 - val_accuracy: 0.4213\n",
      "Epoch 618/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 601548.5625 - accuracy: 0.3567 - val_loss: 882335.0625 - val_accuracy: 0.3234\n",
      "Epoch 619/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 545053.0000 - accuracy: 0.3482 - val_loss: 932606.9375 - val_accuracy: 0.3234\n",
      "Epoch 620/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 509502.8125 - accuracy: 0.3572 - val_loss: 926266.8125 - val_accuracy: 0.3234\n",
      "Epoch 621/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 518168.5000 - accuracy: 0.3316 - val_loss: 1095688.7500 - val_accuracy: 0.3234\n",
      "Epoch 622/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 521143.0000 - accuracy: 0.3529 - val_loss: 854499.6875 - val_accuracy: 0.4213\n",
      "Epoch 623/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 568807.5000 - accuracy: 0.3325 - val_loss: 772570.9375 - val_accuracy: 0.3234\n",
      "Epoch 624/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 522369.2812 - accuracy: 0.3515 - val_loss: 961444.5000 - val_accuracy: 0.3234\n",
      "Epoch 625/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 551639.6250 - accuracy: 0.3425 - val_loss: 844281.4375 - val_accuracy: 0.3234\n",
      "Epoch 626/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 516320.3438 - accuracy: 0.3292 - val_loss: 761084.7500 - val_accuracy: 0.3234\n",
      "Epoch 627/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 550338.8750 - accuracy: 0.3458 - val_loss: 952864.6875 - val_accuracy: 0.3234\n",
      "Epoch 628/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 508032.0625 - accuracy: 0.3515 - val_loss: 811452.4375 - val_accuracy: 0.4213\n",
      "Epoch 629/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 498314.2500 - accuracy: 0.3491 - val_loss: 940232.4375 - val_accuracy: 0.3234\n",
      "Epoch 630/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 547889.9375 - accuracy: 0.3401 - val_loss: 983994.2500 - val_accuracy: 0.3234\n",
      "Epoch 631/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 522808.0312 - accuracy: 0.3264 - val_loss: 759319.9375 - val_accuracy: 0.3234\n",
      "Epoch 632/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 6ms/step - loss: 518856.3438 - accuracy: 0.3297 - val_loss: 860987.9375 - val_accuracy: 0.3234\n",
      "Epoch 633/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 545659.0625 - accuracy: 0.3231 - val_loss: 866704.8750 - val_accuracy: 0.3234\n",
      "Epoch 634/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 515364.7500 - accuracy: 0.3496 - val_loss: 906850.0625 - val_accuracy: 0.3234\n",
      "Epoch 635/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 523639.2188 - accuracy: 0.3458 - val_loss: 815243.4375 - val_accuracy: 0.3234\n",
      "Epoch 636/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 576210.5000 - accuracy: 0.3340 - val_loss: 871171.2500 - val_accuracy: 0.2936\n",
      "Epoch 637/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 538623.2500 - accuracy: 0.3591 - val_loss: 834167.8125 - val_accuracy: 0.4213\n",
      "Epoch 638/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 561566.5000 - accuracy: 0.3430 - val_loss: 839148.3750 - val_accuracy: 0.3234\n",
      "Epoch 639/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 529554.5000 - accuracy: 0.3302 - val_loss: 850721.7500 - val_accuracy: 0.3234\n",
      "Epoch 640/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 513450.8750 - accuracy: 0.3430 - val_loss: 640474.9375 - val_accuracy: 0.3234\n",
      "Epoch 641/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 513084.8750 - accuracy: 0.3586 - val_loss: 901839.0000 - val_accuracy: 0.3234\n",
      "Epoch 642/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 546408.3125 - accuracy: 0.3453 - val_loss: 822873.3125 - val_accuracy: 0.3234\n",
      "Epoch 643/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 572538.0000 - accuracy: 0.3591 - val_loss: 1018627.2500 - val_accuracy: 0.4213\n",
      "Epoch 644/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 564584.6250 - accuracy: 0.3221 - val_loss: 793822.2500 - val_accuracy: 0.3234\n",
      "Epoch 645/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 546827.1875 - accuracy: 0.3633 - val_loss: 970682.2500 - val_accuracy: 0.3234\n",
      "Epoch 646/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 594461.1250 - accuracy: 0.3288 - val_loss: 832612.2500 - val_accuracy: 0.2936\n",
      "Epoch 647/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 603386.5625 - accuracy: 0.3401 - val_loss: 830908.4375 - val_accuracy: 0.3234\n",
      "Epoch 648/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 586893.6250 - accuracy: 0.3411 - val_loss: 887533.5000 - val_accuracy: 0.3234\n",
      "Epoch 649/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 557477.0625 - accuracy: 0.3415 - val_loss: 889877.8125 - val_accuracy: 0.3234\n",
      "Epoch 650/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 567659.5625 - accuracy: 0.3411 - val_loss: 1060576.3750 - val_accuracy: 0.3234\n",
      "Epoch 651/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 565341.3750 - accuracy: 0.3330 - val_loss: 889533.5625 - val_accuracy: 0.4213\n",
      "Epoch 652/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 583024.8750 - accuracy: 0.3387 - val_loss: 747642.0000 - val_accuracy: 0.4213\n",
      "Epoch 653/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 582613.0625 - accuracy: 0.3387 - val_loss: 933861.8750 - val_accuracy: 0.3234\n",
      "Epoch 654/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 534006.8125 - accuracy: 0.3434 - val_loss: 877380.6250 - val_accuracy: 0.3234\n",
      "Epoch 655/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 547982.1250 - accuracy: 0.3486 - val_loss: 1049826.6250 - val_accuracy: 0.3234\n",
      "Epoch 656/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 597863.4375 - accuracy: 0.3425 - val_loss: 989855.0625 - val_accuracy: 0.3234\n",
      "Epoch 657/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 565518.6875 - accuracy: 0.3486 - val_loss: 821962.6250 - val_accuracy: 0.4213\n",
      "Epoch 658/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 529064.8125 - accuracy: 0.3671 - val_loss: 969710.5625 - val_accuracy: 0.3234\n",
      "Epoch 659/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 542116.5625 - accuracy: 0.3539 - val_loss: 868988.1875 - val_accuracy: 0.3234\n",
      "Epoch 660/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 587568.1250 - accuracy: 0.3425 - val_loss: 933979.5000 - val_accuracy: 0.3234\n",
      "Epoch 661/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 549011.0000 - accuracy: 0.3378 - val_loss: 921386.5000 - val_accuracy: 0.4213\n",
      "Epoch 662/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 582776.5625 - accuracy: 0.3496 - val_loss: 845170.3750 - val_accuracy: 0.4213\n",
      "Epoch 663/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 578580.3750 - accuracy: 0.3330 - val_loss: 997528.5000 - val_accuracy: 0.3234\n",
      "Epoch 664/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 598823.6250 - accuracy: 0.3373 - val_loss: 860547.8125 - val_accuracy: 0.2936\n",
      "Epoch 665/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 579654.5625 - accuracy: 0.3449 - val_loss: 1248081.7500 - val_accuracy: 0.3234\n",
      "Epoch 666/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 568072.1250 - accuracy: 0.3543 - val_loss: 785625.8750 - val_accuracy: 0.3234\n",
      "Epoch 667/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 618904.9375 - accuracy: 0.3434 - val_loss: 902444.6875 - val_accuracy: 0.4213\n",
      "Epoch 668/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 588986.7500 - accuracy: 0.3468 - val_loss: 1042257.6875 - val_accuracy: 0.3234\n",
      "Epoch 669/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 592480.7500 - accuracy: 0.3482 - val_loss: 1121371.5000 - val_accuracy: 0.3234\n",
      "Epoch 670/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 672094.6875 - accuracy: 0.3387 - val_loss: 926284.2500 - val_accuracy: 0.4213\n",
      "Epoch 671/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 574672.1250 - accuracy: 0.3553 - val_loss: 953492.1250 - val_accuracy: 0.4213\n",
      "Epoch 672/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 595122.0000 - accuracy: 0.3510 - val_loss: 857284.0625 - val_accuracy: 0.3234\n",
      "Epoch 673/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 614675.5000 - accuracy: 0.3425 - val_loss: 1002988.3750 - val_accuracy: 0.4213\n",
      "Epoch 674/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 595016.2500 - accuracy: 0.3349 - val_loss: 806254.0000 - val_accuracy: 0.3234\n",
      "Epoch 675/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 580107.8750 - accuracy: 0.3449 - val_loss: 937034.0625 - val_accuracy: 0.4213\n",
      "Epoch 676/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 679946.1875 - accuracy: 0.3648 - val_loss: 1160440.3750 - val_accuracy: 0.3234\n",
      "Epoch 677/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 651691.3750 - accuracy: 0.3420 - val_loss: 1181081.6250 - val_accuracy: 0.3234\n",
      "Epoch 678/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 595493.5625 - accuracy: 0.3463 - val_loss: 1038697.6875 - val_accuracy: 0.3234\n",
      "Epoch 679/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 602456.8750 - accuracy: 0.3558 - val_loss: 814398.0625 - val_accuracy: 0.4213\n",
      "Epoch 680/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 624584.1875 - accuracy: 0.3316 - val_loss: 1089740.7500 - val_accuracy: 0.3234\n",
      "Epoch 681/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 588150.9375 - accuracy: 0.3449 - val_loss: 917660.8750 - val_accuracy: 0.4213\n",
      "Epoch 682/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 614787.5625 - accuracy: 0.3311 - val_loss: 890797.1875 - val_accuracy: 0.3234\n",
      "Epoch 683/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 629547.5625 - accuracy: 0.3430 - val_loss: 933770.3750 - val_accuracy: 0.3234\n",
      "Epoch 684/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 635809.4375 - accuracy: 0.3254 - val_loss: 924314.6875 - val_accuracy: 0.3234\n",
      "Epoch 685/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 620602.6875 - accuracy: 0.3434 - val_loss: 891485.6875 - val_accuracy: 0.3234\n",
      "Epoch 686/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 626761.7500 - accuracy: 0.3463 - val_loss: 891002.0000 - val_accuracy: 0.4213\n",
      "Epoch 687/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 614548.9375 - accuracy: 0.3477 - val_loss: 1061896.7500 - val_accuracy: 0.3234\n",
      "Epoch 688/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 574096.3125 - accuracy: 0.3600 - val_loss: 1089697.2500 - val_accuracy: 0.4213\n",
      "Epoch 689/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 709234.7500 - accuracy: 0.3425 - val_loss: 1052380.0000 - val_accuracy: 0.4213\n",
      "Epoch 690/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 674930.0000 - accuracy: 0.3430 - val_loss: 1066764.0000 - val_accuracy: 0.3234\n",
      "Epoch 691/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 658334.5000 - accuracy: 0.3491 - val_loss: 916057.3125 - val_accuracy: 0.3234\n",
      "Epoch 692/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 669032.8750 - accuracy: 0.3458 - val_loss: 1075962.5000 - val_accuracy: 0.3234\n",
      "Epoch 693/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 635127.3750 - accuracy: 0.3311 - val_loss: 1372770.0000 - val_accuracy: 0.3234\n",
      "Epoch 694/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 687375.6250 - accuracy: 0.3406 - val_loss: 931591.6250 - val_accuracy: 0.3234\n",
      "Epoch 695/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 702445.0625 - accuracy: 0.3453 - val_loss: 941334.8750 - val_accuracy: 0.3234\n",
      "Epoch 696/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 676980.4375 - accuracy: 0.3430 - val_loss: 761555.3125 - val_accuracy: 0.3234\n",
      "Epoch 697/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 635826.8750 - accuracy: 0.3420 - val_loss: 955766.7500 - val_accuracy: 0.4213\n",
      "Epoch 698/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 659324.5625 - accuracy: 0.3477 - val_loss: 1111175.1250 - val_accuracy: 0.3234\n",
      "Epoch 699/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 627302.1250 - accuracy: 0.3477 - val_loss: 1340795.1250 - val_accuracy: 0.3234\n",
      "Epoch 700/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 615002.4375 - accuracy: 0.3605 - val_loss: 1215610.0000 - val_accuracy: 0.3234\n",
      "Epoch 701/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 667224.0625 - accuracy: 0.3463 - val_loss: 1074816.5000 - val_accuracy: 0.3234\n",
      "Epoch 702/1000\n",
      "66/66 [==============================] - 0s 8ms/step - loss: 665926.0000 - accuracy: 0.3382 - val_loss: 1077792.6250 - val_accuracy: 0.3234\n",
      "Epoch 703/1000\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 657393.4375 - accuracy: 0.3401 - val_loss: 1029189.7500 - val_accuracy: 0.4213\n",
      "Epoch 704/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 718068.9375 - accuracy: 0.3392 - val_loss: 1336023.7500 - val_accuracy: 0.3234\n",
      "Epoch 705/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 675564.5000 - accuracy: 0.3501 - val_loss: 1376177.6250 - val_accuracy: 0.3234\n",
      "Epoch 706/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 678526.8750 - accuracy: 0.3562 - val_loss: 1003624.5625 - val_accuracy: 0.3234\n",
      "Epoch 707/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 631893.8750 - accuracy: 0.3401 - val_loss: 859658.8750 - val_accuracy: 0.4213\n",
      "Epoch 708/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 730321.0625 - accuracy: 0.3434 - val_loss: 1211365.8750 - val_accuracy: 0.3234\n",
      "Epoch 709/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 651067.5625 - accuracy: 0.3453 - val_loss: 918815.5625 - val_accuracy: 0.3234\n",
      "Epoch 710/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 696727.9375 - accuracy: 0.3401 - val_loss: 783882.8750 - val_accuracy: 0.2936\n",
      "Epoch 711/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 692948.2500 - accuracy: 0.3250 - val_loss: 1094076.5000 - val_accuracy: 0.3234\n",
      "Epoch 712/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 687885.9375 - accuracy: 0.3396 - val_loss: 1154135.1250 - val_accuracy: 0.3234\n",
      "Epoch 713/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 682263.8750 - accuracy: 0.3482 - val_loss: 1177726.3750 - val_accuracy: 0.3234\n",
      "Epoch 714/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 698056.1250 - accuracy: 0.3420 - val_loss: 1158209.3750 - val_accuracy: 0.3234\n",
      "Epoch 715/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 675539.7500 - accuracy: 0.3302 - val_loss: 969017.7500 - val_accuracy: 0.4213\n",
      "Epoch 716/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 712850.5000 - accuracy: 0.3449 - val_loss: 1073465.7500 - val_accuracy: 0.3234\n",
      "Epoch 717/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 695660.7500 - accuracy: 0.3411 - val_loss: 1370678.5000 - val_accuracy: 0.3234\n",
      "Epoch 718/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 691732.6250 - accuracy: 0.3482 - val_loss: 1198232.5000 - val_accuracy: 0.4213\n",
      "Epoch 719/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 700835.1250 - accuracy: 0.3463 - val_loss: 1567173.1250 - val_accuracy: 0.3234\n",
      "Epoch 720/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 696066.8125 - accuracy: 0.3340 - val_loss: 1320942.6250 - val_accuracy: 0.3234\n",
      "Epoch 721/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 711040.1875 - accuracy: 0.3434 - val_loss: 909490.6250 - val_accuracy: 0.3234\n",
      "Epoch 722/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 685946.6250 - accuracy: 0.3392 - val_loss: 991127.4375 - val_accuracy: 0.3234\n",
      "Epoch 723/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 721147.2500 - accuracy: 0.3354 - val_loss: 1085984.6250 - val_accuracy: 0.4213\n",
      "Epoch 724/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 681661.9375 - accuracy: 0.3458 - val_loss: 1022156.8125 - val_accuracy: 0.3234\n",
      "Epoch 725/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 680416.2500 - accuracy: 0.3496 - val_loss: 1290610.3750 - val_accuracy: 0.4213\n",
      "Epoch 726/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 696001.3125 - accuracy: 0.3553 - val_loss: 951596.6875 - val_accuracy: 0.3234\n",
      "Epoch 727/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 719520.8125 - accuracy: 0.3439 - val_loss: 967409.8125 - val_accuracy: 0.2936\n",
      "Epoch 728/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 701513.2500 - accuracy: 0.3548 - val_loss: 1298440.7500 - val_accuracy: 0.3234\n",
      "Epoch 729/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 683867.0625 - accuracy: 0.3434 - val_loss: 1358229.2500 - val_accuracy: 0.3234\n",
      "Epoch 730/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 748042.9375 - accuracy: 0.3188 - val_loss: 1325992.8750 - val_accuracy: 0.3234\n",
      "Epoch 731/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 727228.6875 - accuracy: 0.3325 - val_loss: 909917.6875 - val_accuracy: 0.3234\n",
      "Epoch 732/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 760154.3750 - accuracy: 0.3359 - val_loss: 1233135.6250 - val_accuracy: 0.3234\n",
      "Epoch 733/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 736962.2500 - accuracy: 0.3515 - val_loss: 987258.0000 - val_accuracy: 0.3234\n",
      "Epoch 734/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 689133.0625 - accuracy: 0.3430 - val_loss: 831400.8750 - val_accuracy: 0.2936\n",
      "Epoch 735/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 730211.4375 - accuracy: 0.3292 - val_loss: 1294858.8750 - val_accuracy: 0.4213\n",
      "Epoch 736/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 734984.1250 - accuracy: 0.3363 - val_loss: 1348603.6250 - val_accuracy: 0.3234\n",
      "Epoch 737/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 777695.2500 - accuracy: 0.3392 - val_loss: 1253715.8750 - val_accuracy: 0.3234\n",
      "Epoch 738/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 6ms/step - loss: 711276.4375 - accuracy: 0.3529 - val_loss: 1136287.0000 - val_accuracy: 0.3234\n",
      "Epoch 739/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 740590.6875 - accuracy: 0.3321 - val_loss: 1085065.2500 - val_accuracy: 0.3234\n",
      "Epoch 740/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 750316.5000 - accuracy: 0.3344 - val_loss: 1028126.5000 - val_accuracy: 0.4213\n",
      "Epoch 741/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 756118.0000 - accuracy: 0.3420 - val_loss: 1402714.3750 - val_accuracy: 0.3234\n",
      "Epoch 742/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 778125.0625 - accuracy: 0.3368 - val_loss: 1150732.0000 - val_accuracy: 0.4213\n",
      "Epoch 743/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 751116.8750 - accuracy: 0.3240 - val_loss: 1420841.3750 - val_accuracy: 0.3234\n",
      "Epoch 744/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 758515.7500 - accuracy: 0.3368 - val_loss: 1037591.1250 - val_accuracy: 0.4213\n",
      "Epoch 745/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 812150.3750 - accuracy: 0.3553 - val_loss: 1265881.8750 - val_accuracy: 0.3234\n",
      "Epoch 746/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 733476.5000 - accuracy: 0.3226 - val_loss: 1105885.1250 - val_accuracy: 0.3234\n",
      "Epoch 747/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 765358.7500 - accuracy: 0.3378 - val_loss: 993088.2500 - val_accuracy: 0.4213\n",
      "Epoch 748/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 748859.3125 - accuracy: 0.3477 - val_loss: 1059399.8750 - val_accuracy: 0.3234\n",
      "Epoch 749/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 714785.5000 - accuracy: 0.3510 - val_loss: 1341745.0000 - val_accuracy: 0.4213\n",
      "Epoch 750/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 744028.8750 - accuracy: 0.3259 - val_loss: 1049072.7500 - val_accuracy: 0.3234\n",
      "Epoch 751/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 766516.1250 - accuracy: 0.3662 - val_loss: 1348037.1250 - val_accuracy: 0.3234\n",
      "Epoch 752/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 765490.6875 - accuracy: 0.3444 - val_loss: 1122787.6250 - val_accuracy: 0.3234\n",
      "Epoch 753/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 742908.3750 - accuracy: 0.3548 - val_loss: 1115719.8750 - val_accuracy: 0.3234\n",
      "Epoch 754/1000\n",
      "66/66 [==============================] - 0s 8ms/step - loss: 770055.2500 - accuracy: 0.3382 - val_loss: 1242778.7500 - val_accuracy: 0.4213\n",
      "Epoch 755/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 758354.6875 - accuracy: 0.3434 - val_loss: 1282819.2500 - val_accuracy: 0.3234\n",
      "Epoch 756/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 741548.6875 - accuracy: 0.3505 - val_loss: 1109837.3750 - val_accuracy: 0.3234\n",
      "Epoch 757/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 805101.1875 - accuracy: 0.3458 - val_loss: 1269864.6250 - val_accuracy: 0.3234\n",
      "Epoch 758/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 773106.8750 - accuracy: 0.3382 - val_loss: 1226264.0000 - val_accuracy: 0.2936\n",
      "Epoch 759/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 774839.6250 - accuracy: 0.3434 - val_loss: 1209862.5000 - val_accuracy: 0.3234\n",
      "Epoch 760/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 755999.6250 - accuracy: 0.3491 - val_loss: 1318323.7500 - val_accuracy: 0.3234\n",
      "Epoch 761/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 831100.9375 - accuracy: 0.3439 - val_loss: 967863.0000 - val_accuracy: 0.4213\n",
      "Epoch 762/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 759717.3125 - accuracy: 0.3453 - val_loss: 1333797.0000 - val_accuracy: 0.3234\n",
      "Epoch 763/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 763383.0000 - accuracy: 0.3515 - val_loss: 1082450.7500 - val_accuracy: 0.3234\n",
      "Epoch 764/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 755229.8125 - accuracy: 0.3562 - val_loss: 839475.1875 - val_accuracy: 0.4213\n",
      "Epoch 765/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 808159.6250 - accuracy: 0.3444 - val_loss: 1239767.7500 - val_accuracy: 0.3234\n",
      "Epoch 766/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 832890.3750 - accuracy: 0.3501 - val_loss: 978708.6875 - val_accuracy: 0.2936\n",
      "Epoch 767/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 814122.1875 - accuracy: 0.3297 - val_loss: 1241802.6250 - val_accuracy: 0.3234\n",
      "Epoch 768/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 833709.1875 - accuracy: 0.3434 - val_loss: 771852.0000 - val_accuracy: 0.4213\n",
      "Epoch 769/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 809311.6875 - accuracy: 0.3505 - val_loss: 1015686.0000 - val_accuracy: 0.3234\n",
      "Epoch 770/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 802824.7500 - accuracy: 0.3382 - val_loss: 1309325.6250 - val_accuracy: 0.3234\n",
      "Epoch 771/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 807653.6875 - accuracy: 0.3434 - val_loss: 1515999.3750 - val_accuracy: 0.3234\n",
      "Epoch 772/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 848554.5000 - accuracy: 0.3539 - val_loss: 1434053.1250 - val_accuracy: 0.3234\n",
      "Epoch 773/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 855752.1250 - accuracy: 0.3335 - val_loss: 1300201.1250 - val_accuracy: 0.3234\n",
      "Epoch 774/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 809296.1875 - accuracy: 0.3259 - val_loss: 1362530.0000 - val_accuracy: 0.3234\n",
      "Epoch 775/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 792067.1250 - accuracy: 0.3406 - val_loss: 1341291.8750 - val_accuracy: 0.4213\n",
      "Epoch 776/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 773184.5000 - accuracy: 0.3330 - val_loss: 1155647.1250 - val_accuracy: 0.3234\n",
      "Epoch 777/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 859833.5625 - accuracy: 0.3415 - val_loss: 1164937.2500 - val_accuracy: 0.2936\n",
      "Epoch 778/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 811484.3750 - accuracy: 0.3359 - val_loss: 1245201.3750 - val_accuracy: 0.3234\n",
      "Epoch 779/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 800203.3750 - accuracy: 0.3396 - val_loss: 1306597.8750 - val_accuracy: 0.4213\n",
      "Epoch 780/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 799130.3750 - accuracy: 0.3378 - val_loss: 1311164.5000 - val_accuracy: 0.3234\n",
      "Epoch 781/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 834780.6875 - accuracy: 0.3430 - val_loss: 1110617.3750 - val_accuracy: 0.3234\n",
      "Epoch 782/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 820698.8750 - accuracy: 0.3396 - val_loss: 1153651.5000 - val_accuracy: 0.3234\n",
      "Epoch 783/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 855774.4375 - accuracy: 0.3297 - val_loss: 1402365.8750 - val_accuracy: 0.3234\n",
      "Epoch 784/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 884399.8125 - accuracy: 0.3430 - val_loss: 1016740.5000 - val_accuracy: 0.4213\n",
      "Epoch 785/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 819056.4375 - accuracy: 0.3387 - val_loss: 1707474.2500 - val_accuracy: 0.3234\n",
      "Epoch 786/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 807317.0625 - accuracy: 0.3401 - val_loss: 893215.5625 - val_accuracy: 0.4213\n",
      "Epoch 787/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 864670.2500 - accuracy: 0.3302 - val_loss: 1100821.7500 - val_accuracy: 0.4213\n",
      "Epoch 788/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 867569.0625 - accuracy: 0.3406 - val_loss: 1140126.0000 - val_accuracy: 0.3234\n",
      "Epoch 789/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 786059.9375 - accuracy: 0.3719 - val_loss: 829204.6875 - val_accuracy: 0.2936\n",
      "Epoch 790/1000\n",
      "66/66 [==============================] - 0s 8ms/step - loss: 824614.4375 - accuracy: 0.3439 - val_loss: 1255214.8750 - val_accuracy: 0.4213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 791/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 834567.2500 - accuracy: 0.3188 - val_loss: 1022082.7500 - val_accuracy: 0.3234\n",
      "Epoch 792/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 807549.3750 - accuracy: 0.3288 - val_loss: 1380073.1250 - val_accuracy: 0.4213\n",
      "Epoch 793/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 821684.0625 - accuracy: 0.3496 - val_loss: 1315957.6250 - val_accuracy: 0.4213\n",
      "Epoch 794/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 827340.5625 - accuracy: 0.3543 - val_loss: 1219257.2500 - val_accuracy: 0.3234\n",
      "Epoch 795/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 793869.1875 - accuracy: 0.3458 - val_loss: 993436.8750 - val_accuracy: 0.3234\n",
      "Epoch 796/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 808457.0000 - accuracy: 0.3382 - val_loss: 1038562.5625 - val_accuracy: 0.4213\n",
      "Epoch 797/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 925353.5625 - accuracy: 0.3396 - val_loss: 1010857.9375 - val_accuracy: 0.2936\n",
      "Epoch 798/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 836284.9375 - accuracy: 0.3349 - val_loss: 1102102.8750 - val_accuracy: 0.3234\n",
      "Epoch 799/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 889443.6875 - accuracy: 0.3515 - val_loss: 1255110.2500 - val_accuracy: 0.4213\n",
      "Epoch 800/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 862673.1875 - accuracy: 0.3283 - val_loss: 1177582.6250 - val_accuracy: 0.3234\n",
      "Epoch 801/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 946289.0000 - accuracy: 0.3486 - val_loss: 822337.3750 - val_accuracy: 0.3234\n",
      "Epoch 802/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 870144.3750 - accuracy: 0.3392 - val_loss: 1088899.8750 - val_accuracy: 0.4213\n",
      "Epoch 803/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 870337.9375 - accuracy: 0.3292 - val_loss: 1291033.0000 - val_accuracy: 0.3234\n",
      "Epoch 804/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 860134.7500 - accuracy: 0.3501 - val_loss: 1120935.7500 - val_accuracy: 0.3234\n",
      "Epoch 805/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 825192.1875 - accuracy: 0.3430 - val_loss: 1329979.8750 - val_accuracy: 0.2936\n",
      "Epoch 806/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 828442.1875 - accuracy: 0.3378 - val_loss: 1208102.1250 - val_accuracy: 0.3234\n",
      "Epoch 807/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 820136.6875 - accuracy: 0.3434 - val_loss: 1307434.5000 - val_accuracy: 0.3234\n",
      "Epoch 808/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 804548.6875 - accuracy: 0.3520 - val_loss: 1402871.2500 - val_accuracy: 0.3234\n",
      "Epoch 809/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 845456.3125 - accuracy: 0.3292 - val_loss: 1405738.5000 - val_accuracy: 0.3234\n",
      "Epoch 810/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 936213.4375 - accuracy: 0.3420 - val_loss: 915822.0000 - val_accuracy: 0.2936\n",
      "Epoch 811/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 853680.8125 - accuracy: 0.3401 - val_loss: 1489279.5000 - val_accuracy: 0.3234\n",
      "Epoch 812/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 846164.0625 - accuracy: 0.3572 - val_loss: 1273402.8750 - val_accuracy: 0.3234\n",
      "Epoch 813/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 877233.7500 - accuracy: 0.3501 - val_loss: 1085614.2500 - val_accuracy: 0.3234\n",
      "Epoch 814/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 904645.5625 - accuracy: 0.3444 - val_loss: 1420876.2500 - val_accuracy: 0.2936\n",
      "Epoch 815/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 854571.8750 - accuracy: 0.3477 - val_loss: 1224233.3750 - val_accuracy: 0.2936\n",
      "Epoch 816/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 867097.1250 - accuracy: 0.3529 - val_loss: 1254169.0000 - val_accuracy: 0.3234\n",
      "Epoch 817/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 855314.0625 - accuracy: 0.3392 - val_loss: 1302885.2500 - val_accuracy: 0.4213\n",
      "Epoch 818/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 876384.4375 - accuracy: 0.3515 - val_loss: 1096542.7500 - val_accuracy: 0.2936\n",
      "Epoch 819/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 887456.3125 - accuracy: 0.3491 - val_loss: 1793019.6250 - val_accuracy: 0.3234\n",
      "Epoch 820/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 903071.0000 - accuracy: 0.3155 - val_loss: 1545124.5000 - val_accuracy: 0.3234\n",
      "Epoch 821/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 918602.6875 - accuracy: 0.3501 - val_loss: 1409320.2500 - val_accuracy: 0.3234\n",
      "Epoch 822/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 889199.6875 - accuracy: 0.3411 - val_loss: 1547843.5000 - val_accuracy: 0.3234\n",
      "Epoch 823/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 877248.3125 - accuracy: 0.3406 - val_loss: 1106085.6250 - val_accuracy: 0.3234\n",
      "Epoch 824/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 866366.5625 - accuracy: 0.3482 - val_loss: 1247833.3750 - val_accuracy: 0.4213\n",
      "Epoch 825/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1006564.8125 - accuracy: 0.3477 - val_loss: 1397511.6250 - val_accuracy: 0.3234\n",
      "Epoch 826/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 932691.3125 - accuracy: 0.3401 - val_loss: 1504600.2500 - val_accuracy: 0.4213\n",
      "Epoch 827/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 934668.5000 - accuracy: 0.3396 - val_loss: 1363697.8750 - val_accuracy: 0.4213\n",
      "Epoch 828/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 884638.0000 - accuracy: 0.3486 - val_loss: 1295251.1250 - val_accuracy: 0.3234\n",
      "Epoch 829/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 929257.9375 - accuracy: 0.3283 - val_loss: 1487440.6250 - val_accuracy: 0.3234\n",
      "Epoch 830/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 886237.8125 - accuracy: 0.3382 - val_loss: 1311887.7500 - val_accuracy: 0.3234\n",
      "Epoch 831/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 927239.5000 - accuracy: 0.3415 - val_loss: 1356307.6250 - val_accuracy: 0.4213\n",
      "Epoch 832/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 881466.5625 - accuracy: 0.3439 - val_loss: 1610050.5000 - val_accuracy: 0.3234\n",
      "Epoch 833/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 877409.8750 - accuracy: 0.3378 - val_loss: 1468895.3750 - val_accuracy: 0.3234\n",
      "Epoch 834/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1040630.8750 - accuracy: 0.3420 - val_loss: 1574049.2500 - val_accuracy: 0.3234\n",
      "Epoch 835/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 987425.5625 - accuracy: 0.3292 - val_loss: 1373493.3750 - val_accuracy: 0.3234\n",
      "Epoch 836/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 959413.3125 - accuracy: 0.3567 - val_loss: 1353902.2500 - val_accuracy: 0.3234\n",
      "Epoch 837/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 991152.4375 - accuracy: 0.3354 - val_loss: 1200311.0000 - val_accuracy: 0.4213\n",
      "Epoch 838/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 866616.8750 - accuracy: 0.3430 - val_loss: 1314084.0000 - val_accuracy: 0.3234\n",
      "Epoch 839/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 967984.6250 - accuracy: 0.3595 - val_loss: 1322746.5000 - val_accuracy: 0.4213\n",
      "Epoch 840/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1006569.6875 - accuracy: 0.3392 - val_loss: 1305159.8750 - val_accuracy: 0.3234\n",
      "Epoch 841/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 918648.8125 - accuracy: 0.3458 - val_loss: 1294057.1250 - val_accuracy: 0.4213\n",
      "Epoch 842/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 947485.6875 - accuracy: 0.3349 - val_loss: 1930401.2500 - val_accuracy: 0.3234\n",
      "Epoch 843/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 940342.9375 - accuracy: 0.3359 - val_loss: 1612490.6250 - val_accuracy: 0.3234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 844/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 912131.7500 - accuracy: 0.3131 - val_loss: 1785943.1250 - val_accuracy: 0.3234\n",
      "Epoch 845/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 922485.2500 - accuracy: 0.3444 - val_loss: 1118277.7500 - val_accuracy: 0.3234\n",
      "Epoch 846/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 976037.4375 - accuracy: 0.3572 - val_loss: 1107453.8750 - val_accuracy: 0.4213\n",
      "Epoch 847/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 910634.3125 - accuracy: 0.3411 - val_loss: 1472982.6250 - val_accuracy: 0.3234\n",
      "Epoch 848/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 939045.3750 - accuracy: 0.3430 - val_loss: 1240373.3750 - val_accuracy: 0.3234\n",
      "Epoch 849/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 972162.6250 - accuracy: 0.3306 - val_loss: 1263633.3750 - val_accuracy: 0.3234\n",
      "Epoch 850/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 980997.3125 - accuracy: 0.3207 - val_loss: 1575696.3750 - val_accuracy: 0.3234\n",
      "Epoch 851/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 945446.9375 - accuracy: 0.3505 - val_loss: 1384535.1250 - val_accuracy: 0.3234\n",
      "Epoch 852/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 920885.9375 - accuracy: 0.3633 - val_loss: 1024113.3125 - val_accuracy: 0.4213\n",
      "Epoch 853/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 981425.1875 - accuracy: 0.3472 - val_loss: 1240835.2500 - val_accuracy: 0.4213\n",
      "Epoch 854/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 932432.7500 - accuracy: 0.3420 - val_loss: 1360534.3750 - val_accuracy: 0.4213\n",
      "Epoch 855/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 941292.6875 - accuracy: 0.3463 - val_loss: 1127262.7500 - val_accuracy: 0.2936\n",
      "Epoch 856/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 914729.8125 - accuracy: 0.3524 - val_loss: 1469601.2500 - val_accuracy: 0.3234\n",
      "Epoch 857/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1027839.8750 - accuracy: 0.3543 - val_loss: 1681887.3750 - val_accuracy: 0.3234\n",
      "Epoch 858/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 973825.4375 - accuracy: 0.3439 - val_loss: 1228425.2500 - val_accuracy: 0.3234\n",
      "Epoch 859/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 981362.6250 - accuracy: 0.3269 - val_loss: 1299198.8750 - val_accuracy: 0.3234\n",
      "Epoch 860/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 969658.6250 - accuracy: 0.3430 - val_loss: 956241.6875 - val_accuracy: 0.3234\n",
      "Epoch 861/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 967776.5000 - accuracy: 0.3567 - val_loss: 1244652.3750 - val_accuracy: 0.3234\n",
      "Epoch 862/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1001041.2500 - accuracy: 0.3415 - val_loss: 1105170.5000 - val_accuracy: 0.3234\n",
      "Epoch 863/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1024106.6875 - accuracy: 0.3510 - val_loss: 938925.1875 - val_accuracy: 0.4213\n",
      "Epoch 864/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 978240.6250 - accuracy: 0.3382 - val_loss: 1549900.2500 - val_accuracy: 0.3234\n",
      "Epoch 865/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 983284.5000 - accuracy: 0.3496 - val_loss: 1428789.3750 - val_accuracy: 0.3234\n",
      "Epoch 866/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 948020.2500 - accuracy: 0.3444 - val_loss: 1375933.5000 - val_accuracy: 0.4213\n",
      "Epoch 867/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1046335.9375 - accuracy: 0.3354 - val_loss: 1385580.8750 - val_accuracy: 0.4213\n",
      "Epoch 868/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 995377.5000 - accuracy: 0.3468 - val_loss: 1699308.3750 - val_accuracy: 0.3234\n",
      "Epoch 869/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1033915.9375 - accuracy: 0.3463 - val_loss: 1499894.2500 - val_accuracy: 0.3234\n",
      "Epoch 870/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 916762.8125 - accuracy: 0.3482 - val_loss: 1136500.5000 - val_accuracy: 0.3234\n",
      "Epoch 871/1000\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 957074.7500 - accuracy: 0.3401 - val_loss: 1145424.6250 - val_accuracy: 0.2936\n",
      "Epoch 872/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 952272.4375 - accuracy: 0.3311 - val_loss: 1502918.2500 - val_accuracy: 0.4213\n",
      "Epoch 873/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 948409.3125 - accuracy: 0.3340 - val_loss: 1733270.3750 - val_accuracy: 0.3234\n",
      "Epoch 874/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 918837.0000 - accuracy: 0.3543 - val_loss: 1124482.7500 - val_accuracy: 0.2936\n",
      "Epoch 875/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 956736.1250 - accuracy: 0.3387 - val_loss: 1162165.8750 - val_accuracy: 0.4213\n",
      "Epoch 876/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 942243.0000 - accuracy: 0.3529 - val_loss: 1764748.5000 - val_accuracy: 0.3234\n",
      "Epoch 877/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1030072.1875 - accuracy: 0.3401 - val_loss: 1536705.8750 - val_accuracy: 0.4213\n",
      "Epoch 878/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1027724.4375 - accuracy: 0.3420 - val_loss: 1572062.2500 - val_accuracy: 0.3234\n",
      "Epoch 879/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 980659.2500 - accuracy: 0.3434 - val_loss: 1782439.7500 - val_accuracy: 0.3234\n",
      "Epoch 880/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 977588.6875 - accuracy: 0.3245 - val_loss: 1718306.8750 - val_accuracy: 0.3234\n",
      "Epoch 881/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 958121.5625 - accuracy: 0.3316 - val_loss: 1349109.1250 - val_accuracy: 0.2936\n",
      "Epoch 882/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1043818.3750 - accuracy: 0.3363 - val_loss: 1751353.7500 - val_accuracy: 0.3234\n",
      "Epoch 883/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1021949.0625 - accuracy: 0.3240 - val_loss: 1152980.3750 - val_accuracy: 0.4213\n",
      "Epoch 884/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 982683.9375 - accuracy: 0.3477 - val_loss: 1381118.8750 - val_accuracy: 0.3234\n",
      "Epoch 885/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1056763.1250 - accuracy: 0.3411 - val_loss: 1236904.8750 - val_accuracy: 0.3234\n",
      "Epoch 886/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 981951.5000 - accuracy: 0.3387 - val_loss: 972651.8750 - val_accuracy: 0.2936\n",
      "Epoch 887/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 973624.6250 - accuracy: 0.3501 - val_loss: 1107436.3750 - val_accuracy: 0.3234\n",
      "Epoch 888/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 956135.6250 - accuracy: 0.3392 - val_loss: 1314476.1250 - val_accuracy: 0.3234\n",
      "Epoch 889/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 998525.6250 - accuracy: 0.3425 - val_loss: 1350303.0000 - val_accuracy: 0.3234\n",
      "Epoch 890/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 986102.8125 - accuracy: 0.3548 - val_loss: 1470516.2500 - val_accuracy: 0.4213\n",
      "Epoch 891/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1015550.9375 - accuracy: 0.3449 - val_loss: 1124813.8750 - val_accuracy: 0.4213\n",
      "Epoch 892/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1116817.7500 - accuracy: 0.3316 - val_loss: 1678044.0000 - val_accuracy: 0.4213\n",
      "Epoch 893/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1095061.0000 - accuracy: 0.3363 - val_loss: 1702358.6250 - val_accuracy: 0.3234\n",
      "Epoch 894/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1117417.3750 - accuracy: 0.3344 - val_loss: 1506848.6250 - val_accuracy: 0.4213\n",
      "Epoch 895/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1071391.1250 - accuracy: 0.3396 - val_loss: 1343949.8750 - val_accuracy: 0.4213\n",
      "Epoch 896/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1022924.1250 - accuracy: 0.3396 - val_loss: 1314118.7500 - val_accuracy: 0.4213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 988948.2500 - accuracy: 0.3463 - val_loss: 1630739.6250 - val_accuracy: 0.3234\n",
      "Epoch 898/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1033351.3125 - accuracy: 0.3453 - val_loss: 1654139.1250 - val_accuracy: 0.3234\n",
      "Epoch 899/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 983116.6250 - accuracy: 0.3567 - val_loss: 1558057.3750 - val_accuracy: 0.3234\n",
      "Epoch 900/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 991560.8750 - accuracy: 0.3259 - val_loss: 1505201.6250 - val_accuracy: 0.3234\n",
      "Epoch 901/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1116854.6250 - accuracy: 0.3449 - val_loss: 1194733.5000 - val_accuracy: 0.3234\n",
      "Epoch 902/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1020995.4375 - accuracy: 0.3449 - val_loss: 1740207.3750 - val_accuracy: 0.3234\n",
      "Epoch 903/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1077434.2500 - accuracy: 0.3340 - val_loss: 1210812.5000 - val_accuracy: 0.3234\n",
      "Epoch 904/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1124190.0000 - accuracy: 0.3439 - val_loss: 1130225.8750 - val_accuracy: 0.4213\n",
      "Epoch 905/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 975809.4375 - accuracy: 0.3520 - val_loss: 1266692.3750 - val_accuracy: 0.4213\n",
      "Epoch 906/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1058163.1250 - accuracy: 0.3577 - val_loss: 1536915.1250 - val_accuracy: 0.3234\n",
      "Epoch 907/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1023883.5625 - accuracy: 0.3463 - val_loss: 1576010.1250 - val_accuracy: 0.3234\n",
      "Epoch 908/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1110041.2500 - accuracy: 0.3534 - val_loss: 1656169.6250 - val_accuracy: 0.3234\n",
      "Epoch 909/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1106892.1250 - accuracy: 0.3316 - val_loss: 1446079.7500 - val_accuracy: 0.2936\n",
      "Epoch 910/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1099730.3750 - accuracy: 0.3288 - val_loss: 1723265.6250 - val_accuracy: 0.3234\n",
      "Epoch 911/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1101505.7500 - accuracy: 0.3444 - val_loss: 1407516.3750 - val_accuracy: 0.3234\n",
      "Epoch 912/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1032855.5625 - accuracy: 0.3411 - val_loss: 1874495.1250 - val_accuracy: 0.3234\n",
      "Epoch 913/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 998020.1875 - accuracy: 0.3534 - val_loss: 1586241.3750 - val_accuracy: 0.4213\n",
      "Epoch 914/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1029603.6250 - accuracy: 0.3434 - val_loss: 1283311.6250 - val_accuracy: 0.3234\n",
      "Epoch 915/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1013116.8125 - accuracy: 0.3316 - val_loss: 1600246.2500 - val_accuracy: 0.3234\n",
      "Epoch 916/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1065518.7500 - accuracy: 0.3292 - val_loss: 1439883.5000 - val_accuracy: 0.4213\n",
      "Epoch 917/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1172704.6250 - accuracy: 0.3548 - val_loss: 1679996.1250 - val_accuracy: 0.4213\n",
      "Epoch 918/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1097461.2500 - accuracy: 0.3269 - val_loss: 1505715.7500 - val_accuracy: 0.3234\n",
      "Epoch 919/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1010283.9375 - accuracy: 0.3382 - val_loss: 1386330.3750 - val_accuracy: 0.4213\n",
      "Epoch 920/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1198361.3750 - accuracy: 0.3240 - val_loss: 1658209.0000 - val_accuracy: 0.4213\n",
      "Epoch 921/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1096743.2500 - accuracy: 0.3411 - val_loss: 1003589.7500 - val_accuracy: 0.4213\n",
      "Epoch 922/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1017503.8125 - accuracy: 0.3449 - val_loss: 1155211.5000 - val_accuracy: 0.2936\n",
      "Epoch 923/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1105181.7500 - accuracy: 0.3534 - val_loss: 1325509.1250 - val_accuracy: 0.3234\n",
      "Epoch 924/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1024331.8125 - accuracy: 0.3396 - val_loss: 1331356.8750 - val_accuracy: 0.4213\n",
      "Epoch 925/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1047757.1875 - accuracy: 0.3259 - val_loss: 1511641.8750 - val_accuracy: 0.3234\n",
      "Epoch 926/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1011925.4375 - accuracy: 0.3420 - val_loss: 1388160.5000 - val_accuracy: 0.3234\n",
      "Epoch 927/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 999424.0000 - accuracy: 0.3572 - val_loss: 1129737.7500 - val_accuracy: 0.3234\n",
      "Epoch 928/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 987234.9375 - accuracy: 0.3534 - val_loss: 1305560.7500 - val_accuracy: 0.3234\n",
      "Epoch 929/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1103168.6250 - accuracy: 0.3501 - val_loss: 1273324.3750 - val_accuracy: 0.3234\n",
      "Epoch 930/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1031901.9375 - accuracy: 0.3330 - val_loss: 1239981.2500 - val_accuracy: 0.3234\n",
      "Epoch 931/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1008022.5000 - accuracy: 0.3477 - val_loss: 1122835.6250 - val_accuracy: 0.3234\n",
      "Epoch 932/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1095416.1250 - accuracy: 0.3629 - val_loss: 1194280.2500 - val_accuracy: 0.4213\n",
      "Epoch 933/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1083432.7500 - accuracy: 0.3472 - val_loss: 1254892.3750 - val_accuracy: 0.3234\n",
      "Epoch 934/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1106197.5000 - accuracy: 0.3387 - val_loss: 1157355.2500 - val_accuracy: 0.4213\n",
      "Epoch 935/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1086670.1250 - accuracy: 0.3539 - val_loss: 1039686.8125 - val_accuracy: 0.4213\n",
      "Epoch 936/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1077667.1250 - accuracy: 0.3468 - val_loss: 1045944.1250 - val_accuracy: 0.3234\n",
      "Epoch 937/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1146211.5000 - accuracy: 0.3363 - val_loss: 1284279.0000 - val_accuracy: 0.4213\n",
      "Epoch 938/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1134717.1250 - accuracy: 0.3330 - val_loss: 1241706.7500 - val_accuracy: 0.4213\n",
      "Epoch 939/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1161378.0000 - accuracy: 0.3558 - val_loss: 1847147.8750 - val_accuracy: 0.3234\n",
      "Epoch 940/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1101835.6250 - accuracy: 0.3629 - val_loss: 1542998.0000 - val_accuracy: 0.4213\n",
      "Epoch 941/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1207485.6250 - accuracy: 0.3510 - val_loss: 888326.5625 - val_accuracy: 0.4213\n",
      "Epoch 942/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1086651.7500 - accuracy: 0.3477 - val_loss: 1511859.7500 - val_accuracy: 0.3234\n",
      "Epoch 943/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1133920.6250 - accuracy: 0.3387 - val_loss: 1478202.8750 - val_accuracy: 0.4213\n",
      "Epoch 944/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1069869.0000 - accuracy: 0.3534 - val_loss: 1304471.3750 - val_accuracy: 0.4213\n",
      "Epoch 945/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1067349.5000 - accuracy: 0.3349 - val_loss: 1015738.2500 - val_accuracy: 0.4213\n",
      "Epoch 946/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1129531.6250 - accuracy: 0.3330 - val_loss: 1189042.6250 - val_accuracy: 0.3234\n",
      "Epoch 947/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1115291.7500 - accuracy: 0.3292 - val_loss: 1287521.0000 - val_accuracy: 0.4213\n",
      "Epoch 948/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1146617.1250 - accuracy: 0.3543 - val_loss: 1167769.6250 - val_accuracy: 0.3234\n",
      "Epoch 949/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1133467.6250 - accuracy: 0.3382 - val_loss: 1023843.1250 - val_accuracy: 0.4213\n",
      "Epoch 950/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1277147.7500 - accuracy: 0.3297 - val_loss: 1635192.8750 - val_accuracy: 0.4213\n",
      "Epoch 951/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1158435.5000 - accuracy: 0.3453 - val_loss: 1598215.6250 - val_accuracy: 0.3234\n",
      "Epoch 952/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1082358.7500 - accuracy: 0.3292 - val_loss: 1345570.8750 - val_accuracy: 0.3234\n",
      "Epoch 953/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1125180.5000 - accuracy: 0.3392 - val_loss: 1040026.6875 - val_accuracy: 0.4213\n",
      "Epoch 954/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1202103.2500 - accuracy: 0.3472 - val_loss: 1346878.1250 - val_accuracy: 0.3234\n",
      "Epoch 955/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1168420.3750 - accuracy: 0.3415 - val_loss: 1265855.7500 - val_accuracy: 0.3234\n",
      "Epoch 956/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1230987.7500 - accuracy: 0.3496 - val_loss: 1573796.5000 - val_accuracy: 0.3234\n",
      "Epoch 957/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1160326.3750 - accuracy: 0.3638 - val_loss: 1490734.8750 - val_accuracy: 0.3234\n",
      "Epoch 958/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1195116.1250 - accuracy: 0.3610 - val_loss: 1557464.7500 - val_accuracy: 0.3234\n",
      "Epoch 959/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1187809.0000 - accuracy: 0.3444 - val_loss: 1972293.7500 - val_accuracy: 0.3234\n",
      "Epoch 960/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1244143.0000 - accuracy: 0.3316 - val_loss: 1549298.8750 - val_accuracy: 0.1915\n",
      "Epoch 961/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1263778.0000 - accuracy: 0.3529 - val_loss: 2120020.0000 - val_accuracy: 0.3234\n",
      "Epoch 962/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1231016.7500 - accuracy: 0.3425 - val_loss: 2090711.7500 - val_accuracy: 0.3234\n",
      "Epoch 963/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1203925.2500 - accuracy: 0.3515 - val_loss: 2040348.3750 - val_accuracy: 0.4213\n",
      "Epoch 964/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1197286.3750 - accuracy: 0.3439 - val_loss: 1426218.5000 - val_accuracy: 0.3234\n",
      "Epoch 965/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1246811.8750 - accuracy: 0.3420 - val_loss: 1883149.1250 - val_accuracy: 0.4213\n",
      "Epoch 966/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1195280.1250 - accuracy: 0.3349 - val_loss: 2083365.0000 - val_accuracy: 0.3234\n",
      "Epoch 967/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1255347.3750 - accuracy: 0.3387 - val_loss: 2100385.2500 - val_accuracy: 0.3234\n",
      "Epoch 968/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1159814.1250 - accuracy: 0.3577 - val_loss: 1503598.0000 - val_accuracy: 0.2936\n",
      "Epoch 969/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1187861.3750 - accuracy: 0.3340 - val_loss: 1706628.8750 - val_accuracy: 0.4213\n",
      "Epoch 970/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1124467.5000 - accuracy: 0.3406 - val_loss: 1500068.5000 - val_accuracy: 0.4213\n",
      "Epoch 971/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1198086.7500 - accuracy: 0.3311 - val_loss: 1636578.6250 - val_accuracy: 0.3234\n",
      "Epoch 972/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1155387.2500 - accuracy: 0.3458 - val_loss: 1659254.7500 - val_accuracy: 0.3234\n",
      "Epoch 973/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1235648.3750 - accuracy: 0.3392 - val_loss: 1601623.1250 - val_accuracy: 0.4213\n",
      "Epoch 974/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1157646.7500 - accuracy: 0.3420 - val_loss: 1444293.1250 - val_accuracy: 0.3234\n",
      "Epoch 975/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1207156.7500 - accuracy: 0.3562 - val_loss: 1894870.6250 - val_accuracy: 0.4213\n",
      "Epoch 976/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1204344.2500 - accuracy: 0.3396 - val_loss: 1900997.1250 - val_accuracy: 0.3234\n",
      "Epoch 977/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1193438.7500 - accuracy: 0.3235 - val_loss: 1982516.2500 - val_accuracy: 0.3234\n",
      "Epoch 978/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1181270.1250 - accuracy: 0.3439 - val_loss: 1436353.8750 - val_accuracy: 0.3234\n",
      "Epoch 979/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1186610.7500 - accuracy: 0.3406 - val_loss: 1817630.5000 - val_accuracy: 0.3234\n",
      "Epoch 980/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1238931.3750 - accuracy: 0.3425 - val_loss: 1692310.3750 - val_accuracy: 0.3234\n",
      "Epoch 981/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1211901.8750 - accuracy: 0.3340 - val_loss: 1804479.7500 - val_accuracy: 0.3234\n",
      "Epoch 982/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1161581.7500 - accuracy: 0.3491 - val_loss: 1794727.7500 - val_accuracy: 0.3234\n",
      "Epoch 983/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1192121.2500 - accuracy: 0.3458 - val_loss: 1499327.7500 - val_accuracy: 0.4213\n",
      "Epoch 984/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1287635.1250 - accuracy: 0.3401 - val_loss: 1659054.2500 - val_accuracy: 0.3234\n",
      "Epoch 985/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1202478.7500 - accuracy: 0.3354 - val_loss: 1691717.7500 - val_accuracy: 0.3234\n",
      "Epoch 986/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1161656.5000 - accuracy: 0.3619 - val_loss: 1598206.8750 - val_accuracy: 0.3234\n",
      "Epoch 987/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1318524.8750 - accuracy: 0.3325 - val_loss: 1633659.1250 - val_accuracy: 0.3234\n",
      "Epoch 988/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1169152.8750 - accuracy: 0.3411 - val_loss: 1416274.7500 - val_accuracy: 0.4213\n",
      "Epoch 989/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1354433.2500 - accuracy: 0.3444 - val_loss: 1762046.8750 - val_accuracy: 0.3234\n",
      "Epoch 990/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1267249.2500 - accuracy: 0.3420 - val_loss: 1573142.8750 - val_accuracy: 0.3234\n",
      "Epoch 991/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1250759.5000 - accuracy: 0.3520 - val_loss: 1696702.6250 - val_accuracy: 0.3234\n",
      "Epoch 992/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1203912.6250 - accuracy: 0.3548 - val_loss: 1676745.5000 - val_accuracy: 0.4213\n",
      "Epoch 993/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1282961.8750 - accuracy: 0.3387 - val_loss: 1662575.1250 - val_accuracy: 0.2936\n",
      "Epoch 994/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1364291.0000 - accuracy: 0.3378 - val_loss: 1551233.6250 - val_accuracy: 0.3234\n",
      "Epoch 995/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1266040.3750 - accuracy: 0.3344 - val_loss: 2195647.7500 - val_accuracy: 0.3234\n",
      "Epoch 996/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1205218.3750 - accuracy: 0.3501 - val_loss: 2425215.5000 - val_accuracy: 0.3234\n",
      "Epoch 997/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1363632.3750 - accuracy: 0.3316 - val_loss: 1205635.8750 - val_accuracy: 0.3234\n",
      "Epoch 998/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1300338.3750 - accuracy: 0.3325 - val_loss: 1649293.6250 - val_accuracy: 0.4213\n",
      "Epoch 999/1000\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 1395557.2500 - accuracy: 0.3472 - val_loss: 2236695.0000 - val_accuracy: 0.3234\n",
      "Epoch 1000/1000\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 1277279.6250 - accuracy: 0.3586 - val_loss: 1553429.7500 - val_accuracy: 0.2936\n",
      "Test loss: 4697685.5\n",
      "Test accuracy: 0.23172242939472198\n"
     ]
    }
   ],
   "source": [
    "#some k-fold code adapted from:\n",
    "#https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "notebook_path = 'path\\\\to\\\\where\\\\inputfiles\\\\are'\n",
    "\n",
    "num_classes = 4\n",
    "input_shape = (225, 1)\n",
    "batch_size  = 32\n",
    "epochs = 1000\n",
    "num_iter = 1 #in case you want to run more than one iteration and take an average to reduce variance\n",
    "\n",
    "trainin = open(notebook_path+'all_trainin.txt', 'r') #already appended with bias value\n",
    "trainout = open(notebook_path+'all_trainout.txt', 'r')\n",
    "testin = open(notebook_path+'all_testin.txt', 'r')\n",
    "testout = open(notebook_path+'all_testout.txt', 'r')\n",
    "\n",
    "trainin_matrix = np.zeros((0, 225))\n",
    "trainout_matrix = np.zeros((0, 4))\n",
    "testin_matrix = np.zeros((0, 225))\n",
    "testout_matrix = np.zeros((0, 4))\n",
    "\n",
    "while True:\n",
    "    inline = trainin.readline()\n",
    "    outline = trainout.readline()\n",
    "    if not inline or inline == '':\n",
    "        break\n",
    "    in_num = [float(numeric_string) for numeric_string in inline.split()]\n",
    "    out_num = [float(numeric_string) for numeric_string in outline.split()]\n",
    "    trainin_matrix = np.append(trainin_matrix,[in_num], axis=0)\n",
    "    trainout_matrix = np.append(trainout_matrix,[out_num], axis=0)\n",
    "\n",
    "while True:\n",
    "    inline = testin.readline()\n",
    "    outline = testout.readline()\n",
    "    if not inline or inline == '':\n",
    "        break\n",
    "    in_num = [float(numeric_string) for numeric_string in inline.split()]\n",
    "    out_num = [float(numeric_string) for numeric_string in outline.split()]\n",
    "    testin_matrix = np.append(testin_matrix,[in_num], axis=0)\n",
    "    testout_matrix = np.append(testout_matrix,[out_num], axis=0)\n",
    "\n",
    "trainin_matrix = trainin_matrix.reshape(trainin_matrix.shape[0],trainin_matrix.shape[1], 1, 1)\n",
    "testin_matrix = testin_matrix.reshape(testin_matrix.shape[0],testin_matrix.shape[1], 1, 1)\n",
    "\n",
    "print(trainin_matrix.shape)\n",
    "print(trainout_matrix.shape)\n",
    "print(testin_matrix.shape)\n",
    "print(testout_matrix.shape)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv1D(32, kernel_size=3, activation=\"relu\", use_bias=False),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Conv1D(64, kernel_size=3, activation=\"relu\", use_bias=False),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "avg = 0\n",
    "\n",
    "history = ''\n",
    "for i in range(num_iter):\n",
    "    \n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    history = model.fit(trainin_matrix, trainout_matrix, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "    score = model.evaluate(testin_matrix, testout_matrix, verbose=0)\n",
    "\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n",
    "    \n",
    "    avg += float(score[1])\n",
    "\n",
    "avg /= num_iter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69fd1c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([testin_matrix[374],]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ac93f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA4/klEQVR4nO2deZwdRbm/n3f2LJM9BLJAAoSwakICsriwKvsii4IgcFX0Cle4VxHwIotXfy5XUfEioIgiIKsCEcIum+wJIIQsJIFAJiHJZJJMZpKZZJb390d3z/Q5031On6XnzEy/z+eTzOnu6qq3u6rrW/VWdbWoKoZhGEZyKSu1AYZhGEZpMSEwDMNIOCYEhmEYCceEwDAMI+GYEBiGYSQcEwLDMIyEY0JgJAoR+ZOI/DBi2OUickTcNhlGqTEhMAzDSDgmBIbRDxGRilLbYAwcTAiMPofrkrlERN4Skc0i8gcRGScij4hIk4g8KSIjfeFPEJF3RGSjiDwjInv4js0Qkdfd8+4GatLSOk5E3nTPfVFEPhbRxmNF5A0R2SQiK0Tk6rTjn3Tj2+geP9fdP0hEfiEiH4hIo4j80913iIjUBdyHI9zfV4vIfSJyu4hsAs4Vkf1F5CU3jY9E5P9EpMp3/l4i8oSIrBeRNSLyPRHZXkS2iMhoX7h9RaReRCqjXLsx8DAhMPoqpwBHArsBxwOPAN8DxuKU228BiMhuwJ3Axe6xOcDfRaTKrRQfAG4DRgH3uvHinjsDuAX4OjAauAmYLSLVEezbDHwZGAEcC/y7iJzkxruTa+9vXJumA2+65/0cmAkc5Nr0XaAz4j05EbjPTfMOoAP4T2AMcCBwOPBN14Za4EngUWA8sCvwlKquBp4BTvfFezZwl6q2RbTDGGCYEBh9ld+o6hpVXQk8D7yiqm+oaitwPzDDDfcF4GFVfcKtyH4ODMKpaA8AKoFfqWqbqt4HvOZL43zgJlV9RVU7VPVWYKt7XkZU9RlVfVtVO1X1LRwx+ox7+EzgSVW90023QVXfFJEy4N+Ai1R1pZvmi6q6NeI9eUlVH3DTbFHVear6sqq2q+pyHCHzbDgOWK2qv1DVVlVtUtVX3GO3AmcBiEg5cAaOWBoJxYTA6Kus8f1uCdge6v4eD3zgHVDVTmAFMME9tlJTV1b8wPd7J+Dbrmtlo4hsBCa552VERD4hIk+7LpVG4Bs4LXPcOJYFnDYGxzUVdCwKK9Js2E1EHhKR1a676P9FsAHgQWBPEZmC0+tqVNVX87TJGACYEBj9nVU4FToAIiI4leBK4CNggrvPY0ff7xXAj1R1hO/fYFW9M0K6fwFmA5NUdThwI+ClswLYJeCcdUBryLHNwGDfdZTjuJX8pC8VfAOwCJiqqsNwXGd+G3YOMtztVd2D0ys4G+sNJB4TAqO/cw9wrIgc7g52fhvHvfMi8BLQDnxLRCpF5PPA/r5zfw98w23di4gMcQeBayOkWwusV9VWEdkfxx3kcQdwhIicLiIVIjJaRKa7vZVbgGtFZLyIlIvIge6YxLtAjZt+JXAFkG2sohbYBDSLyO7Av/uOPQTsICIXi0i1iNSKyCd8x/8MnAucgAlB4jEhMPo1qroYp2X7G5wW9/HA8aq6TVW3AZ/HqfDW44wn/M137lzga8D/ARuApW7YKHwT+IGINAFX4giSF++HwDE4orQeZ6D44+7h7wBv44xVrAd+CpSpaqMb5804vZnNQMosogC+gyNATTiidrfPhiYct8/xwGpgCXCo7/gLOIPUr6uq311mJBCxD9MYRjIRkX8Af1HVm0tti1FaTAgMI4GIyH7AEzhjHE2ltscoLeYaMoyEISK34rxjcLGJgAHWIzAMw0g81iMwDMNIOP1u4aoxY8bo5MmTS22GYRhGv2LevHnrVDX93RSgHwrB5MmTmTt3bqnNMAzD6FeISOg0YXMNGYZhJBwTAsMwjIRjQmAYhpFw+t0YQRBtbW3U1dXR2tpaalNipaamhokTJ1JZad8PMQyjeAwIIairq6O2tpbJkyeTutDkwEFVaWhooK6ujilTppTaHMMwBhADwjXU2trK6NGjB6wIAIgIo0ePHvC9HsMwep8BIQTAgBYBjyRco2EYvc+AEYKsqMKWBujsKLUlhmEYfYrkCMG2Ztj4IWxaWfSoN27cyG9/+9uczzvmmGPYuHFj0e0xDMPIheQIgdcT6GgvetRhQtDenjmtOXPmMGLEiKLbYxiGkQsDYtZQqbnssstYtmwZ06dPp7KykpqaGkaOHMmiRYt49913Oemkk1ixYgWtra1cdNFFnH/++UD3chnNzc0cffTRfPKTn+TFF19kwoQJPPjggwwaNKjEV2YYRhIYcEJwzd/fYcGqTT0PdLZDeyuUbYSKNTnFuef4YVx1/F6hx3/yk58wf/583nzzTZ555hmOPfZY5s+f3zXN85ZbbmHUqFG0tLSw3377ccoppzB69OiUOJYsWcKdd97J73//e04//XT++te/ctZZZ+Vkp2EYRj4MOCHoC+y///4pc/2vu+467r//fgBWrFjBkiVLegjBlClTmD59OgAzZ85k+fLlvWWuYRgJZ8AJQWjLvWUjbHgfqofD6J1jtWHIkCFdv5955hmefPJJXnrpJQYPHswhhxwS+C5AdXV11+/y8nJaWlpitdEwDMMjOYPFMVJbW0tTU/AX/xobGxk5ciSDBw9m0aJFvPzyy71snWEYRmYGXI+gFIwePZqDDz6Yvffem0GDBjFu3LiuY0cddRQ33ngje+yxB9OmTeOAAw4ooaWGYRg96XffLJ41a5amf5hm4cKF7LHHHplP7EXXUJxEulbDMIw0RGSeqs4KOmauIcMwjIRjQmAYhpFwTAgMwzASjgmBYRhGwjEhMAzDSDgmBIZhGAnHhKAI5LsMNcCvfvUrtmzZUmSLDMMwomNCUARMCAzD6M/Ym8VFwL8M9ZFHHsl2223HPffcw9atWzn55JO55ppr2Lx5M6effjp1dXV0dHTw/e9/nzVr1rBq1SoOPfRQxowZw9NPP13qSzEMI4EMPCF45DJY/XbP/Z3t0N4CZRVQkeM6/9vvA0f/JPSwfxnqxx9/nPvuu49XX30VVeWEE07gueeeo76+nvHjx/Pwww8DzhpEw4cP59prr+Xpp59mzJgxudlkGIZRJMw1VGQef/xxHn/8cWbMmMG+++7LokWLWLJkCfvssw9PPPEEl156Kc8//zzDhw8vtamGYRjAQOwRhLXce2mtIVXl8ssv5+tf/3qPY6+//jpz5szhiiuu4PDDD+fKK6+MzQ7DMIyoWI+gCPiXof7c5z7HLbfcQnNzMwArV65k7dq1rFq1isGDB3PWWWdxySWX8Prrr/c41zAMoxQMvB5BCfAvQ3300Udz5plncuCBBwIwdOhQbr/9dpYuXcoll1xCWVkZlZWV3HDDDQCcf/75HHXUUYwfP94Giw3DKAm2DHU/w5ahNgwjH0q2DLWIHCUii0VkqYhcFnD8XBGpF5E33X9fjdMewzAMoyexuYZEpBy4HjgSqANeE5HZqrogLejdqnphXHYYhmEYmYmzR7A/sFRV31PVbcBdwIlxJdbfXFz5kIRrNAyj94lTCCYAK3zbde6+dE4RkbdE5D4RmRQUkYicLyJzRWRufX19j+M1NTU0NDQM6IpSVWloaKCmpqbUphiGMcAo9ayhvwN3qupWEfk6cCtwWHogVf0d8DtwBovTj0+cOJG6ujqCRKKLthbYXA+VTbB2a7Hs71VqamqYOHFiqc0wDGOAEacQrAT8LfyJ7r4uVLXBt3kz8LN8EqqsrGTKlCmZAy18CB77Ekw7Bs64M59kDMMwBiRxuoZeA6aKyBQRqQK+CMz2BxCRHXybJwALY7NGJLaoDcMw+jOx9QhUtV1ELgQeA8qBW1T1HRH5ATBXVWcD3xKRE4B2YD1wblz2GIZhGMHEOkagqnOAOWn7rvT9vhy4PE4bfAn3SjKGYRj9DVtryDAMI+EkRwhsjMAwDCOQ5AiBYRiGEUhyhMDGCAzDMAJJjhAYhmEYgSRHCGyMwDAMI5DkCIFhGIYRiAmBYRhGwkmeECyeA81rS22FYRhGnyF5QgBww8GltsAwDKPPkEwh2Gw9AsMwDI9kCoFhGIbRRXKEwF4oMwzDCCQ5QmAYhmEEkhwhsBfKDMMwAkmOEBiGYRiBJEcIbIzAMAwjkOQIgWEYhhFIcoTAxggMwzACSY4QmGvIMAwjkOQIASYEhmEYQSRICAzDMIwgkiME5hoyDMMIJDlCYK4hwzCMQJIjBNYjMAzDCCQ5QmAYhmEEUlFqA3qPtB6BancvQcT9rVBWnnqsrMzd7gQkNb62Fudn9VDnb2enG5cbtqwMWjZCRQ2UV8K2Zqgc4qQB0NoI1cN85+AcS49HpPs9iE4vXJnze1szVA31XYd73LO1y373+rY2Qc3w7rTLylLjTaesDFo3dafhpVtWBh3tTjxDRjvHOtpgcz3U7uCkV5bWzvDs2LoJBo3oTlPEiUc7obMdhox1wjWvgbIKGDy6Zz5599eL04vDi7eszPkSXdUQqBjUnWbXtSp0bANxbdy22cknKYPyKid8da1zv7z75JWJ9q3Q3uLsR7rLTesmqBzshGnb4tyz9lbnWHlV9z33X4t3f8vKHTvbNneXl85O2NLgHqtx421xzqmocf6pwrYmEDdMeUXqPfH/9V+Dh4hTRmuGd+dNzXAnL7rKlnSH3boJqmp7xu0vG/6yKGWpYdLLZ0q++ra98uKxdZNz77y/Hv4ylhK+ycl77/nxP79eWamohspBznntrc7x8qqedoBTrqUMBo108qNlo1OeVKGzw7FL1T3u3ufWxu7zO7bBoFFO/lbV+p67Dife1kanvHn3q6sO0FRbYnofKjlCkP4APHk1vPCrnuG+PBuWPA4v/Z+zfXUjXDMic9z/vcapGH46OXX/2Q/AbScFn3PENfDkVT33n/YnuPdc2P04WPSQs2/YBPivBdBcDz/f1dl3eR38eGJmuwBOvB5euh7WLujeN3xHaPzQ+X3WX2HkFPjNvsHnf2cJ/Hxq90N4+p/hni/DGXfD3FtgyWPOPdv5M3DXl5zt2vHQtAoung8jJnXHdd958M79zu+Z58K8P2W338/Oh8J7T3dvf/15uOlT7oZbIc88D+b9EQ64AF6+PvX80251KrcHL8gtXXCu+9HvQcdWp8L27p/HmffAX04PPnfsHvDxL6bm97RjYfHDzn288ws9zznpBnjg3zPbNPWzTln12OUwOPt+uOGg1PyedozzidbLVsAfj4H6hY7gTv4UzDgL7v96WsTuvQxj+pdg+33g0cucOJY/7+y/eD78au/UsFM+A+fMzvwMfeYyePYn3dsjp8Cw8fDBCxku3uXS5U7lC04akw6ADe87jYgw9j4V5t/nlNNvL+y2bdAoaFnfHW7YRCe/Z54Lz/2vs2+vk53tP58Ix/4CljwJ7z6SGv95j8Afj85s93ffh0UPw+wLex778oNO/H7GTIONH8IVqzPHmyfJEYL0gv3q74KDLXsKXrkxt6jbtkBTQAa990z4Od7Dk87cPzp/PREA2LTS+euvfLY0RLPt7XtTK4X0eN59DHY6KPz8Le6DsXWT8/e1Pzh/Fz8MK+c5v72HrmlV6t91i1OFwBMBiCYCZRVOheXhFwGAuld9G27+zvtjz7Q8GpbA8n9mTzeIhX+HTXXhxxfMDj9Wv7Bnfi9+2D3vgeBz/nVXdpv8IgCw7B/O3/T8XjzH+btlHax5u3v/8udh/PSAiLOMp715B4zbuzsOj3WLe4Z9/9nMcQHM/UPq9ob3nX9RaF7bLQQAK17Ofs78+5y/Xjn18IsAdOd300fd+9YuhEZ3/8rXe4oAZH7uPZrXwNv3BB9b8kTPfUH3togkZ4wgp8HiHLtfYXFriLulGBR18DvD9Wa6hq4uvBum2OPx/m56rsR574uZXm/baeROAiaaJEcI4kRdn3Pg/jjT7AWipNMlBEW2ScrzP7ffC8HAr3z6DQkQaxOCIHIdkAkrKHG2JIoZd6brLaUQlCVYCBLQCu03mBAMIGKtlMMeZusRFESihWDgVz79hgTkRXKEINaudljcpUizBOl0iWyRbSrENdTrrpU80wsdX7IeQZ8hPS8GYN7EKgQicpSILBaRpSJyWYZwp4iIisisOO2JDe0MLhzWIyiMsgImtVmPwCgW6XkxAPMmNiEQkXLgeuBoYE/gDBHZMyBcLXAR8EpctgAxzxoqwWBxZ0cRI8s0RhClR9AXXUO93GozIRi4mBAUxP7AUlV9T1W3AXcBJwaE+x/gp0BrjLaQU9e9aIPFcfYIiigENlhcOHkLQQmmHhu5YUJQEBOAFb7tOndfFyKyLzBJVR/OFJGInC8ic0Vkbn19fX7WxD1Y3NuuIf+LVnESSQjSlw8oEv1q+mi+YwS92IgYgL7tXsGEID5EpAy4Fvh2trCq+jtVnaWqs8aOHRu/cX5XSSTXSAladb3mGsqlR1DkiiYRPYIBJASl0JneEDcbLC6IlYBvfQEmuvs8aoG9gWdEZDlwADA7vgHjIs/qSAlTAtdQUYUgA5GuoUQ9gkx509vz8/uFEBQxzt7uAYfSG0IQQ4+gj4lJnELwGjBVRKaISBXwRaBrQRZVbVTVMao6WVUnAy8DJ6jq3FisKXbXvUfcQQ9GPmlGPKdPuYb64hhBUH7kH1329PrBC2WxV9QxNrbiODd6ImmbxRCCvuVeik0IVLUduBB4DFgI3KOq74jID0TkhLjSzWBR9KD+wdNcKsIe+/MppBEHqvvkYHEvu4ZytVs7Y1vGN/9r7813UGJ+G70U6y0VWqHm1eMvxn3sWz2CWFcfVdU5wJy0fVeGhD0kTlvyJmpF2BtdZX8SvdUjiJJOf1lrqC++19FfXUPFjL+/CYH1CPoxOQ345NMjKJYQRPR799ZgcZR0+qJrqL8sAmhCUKBrqNBrylEIuj5SVWiyJgQlIk8/X+QeQZFaoFEHQKP2CAp115SyR5Dri33Z6JNC0IszzgLLaBFdFP2yR5Cj6zfsWY8j3V4kOULQo0eQoaWb4v+M2GIIfKDyeMgiC0HEHkGUApfJbx6pRxDXrKEiF8+C7MsmSv1graEBKQQF2p+za6hYPYK+NUYQ6UkTkb+JyLHu3P9+SjTXUFNrO9va01oAWaMOaSXk477JJFB9tkegqX+LRbbilmt6oYId6eTMh8O++Zw12pD8LuZkgK44izhuUswxsT7fI/Bda8J7BL8FzgSWiMhPRGRajDb1EsEP9pML17CtI0chQHN/MPJyCfjOKWaPIBOFjBEUqgtFb3eUYCnyruO55XfrthgmAxSr15pT/JFOLCTRAs6NeH4PISjCPeuPQqCqT6rql4B9geXAkyLyooicJyKVcRpYNHq4hoIzoqNT0XzeLA6Mr8gvPKX4KospBJmmYWbqoaS7hIo737p5W5FbxXFOH81WoeSY32s3tRRoT8S08s2joPuY70y2YvQI8n5PKNfB4mIJQT90DQGIyGjgXOCrwBvAr3GEIeBLy32ROF8oC3MNZeoR5DFbJC/XUKE9gkzppAlBkafZvdeQpTLMNf5SfJwo2/GQ/WXSW2MERWyZ9kshyHWwWAtPM2q6vUik9whE5H5gGnAbcLyqfuQeultE4nkTuNhEzDSRNMkoaNZQphZtHq6hmISgvnkroSs4ZUonXQCKLASarZ2SsxCUctZQbvktcbixBrQQxDg+ETpraOAIQdQewXWquqeq/tgnAgCoav/8mExUovrIcx0sDhWmaK6h2W+sCA+Xck52+3/+2KLwgz2uIc1f6t/X4x4UVplJNjdOPoPFeVOgLTnmtwlBjufmLQQ5jIFBWo8gLM3s7se36jb0Ke9QVCHYU0RGeBsiMlJEvhmPSXER9a6nZWLUefSBQhChNd3jnOCC2dmZOiA99/2Iy3FHeECaW9vCD6bbkzJwFq9rSLMIwZ9eWJZjhDHOGspWoeSY3+XE0GIMsOGjjVvyjCvgfuQ7c6oQChWCKDaH9QhC08xexn76yAI+WJ/nvY+BqELwNVXd6G2o6gbga7FYFBdRXUPpOyJPn+wZv2Y4d/m6psD9Ta3bAvev3tSacg0VUSuKCA+IZgqTfg0BQvDysnU8Ov+jogtBp2Yunqs2bM4twgKaYMvqm7PEne8YQbBNZb3UI1jXtLWI8ffSirgpaXr3Kc/7FakXEzJ9tIB3QMpQ1m8OftYz0ZSp0VYAUYWgXHz9dPczlFWxWFRqpOs/hwJcQw1N4Yq/rin4g2x164Mrt9a2jpQ0yok6ayhzoVRVOjpyEYLusFvbnEL5rxXr+cbtrxdfCLJ0sXOuLAuw5+2VjYXFneNgcW+5hqSYPY/eWv/Kj3ayqbWNe1/7IK/TW9siVKy++9bR2UGLO7X3w4bgxsHbKzdmjTJfoX/gzVV5nZeNqELwKM7A8OEicjhwp7tvwCGkDxZHE4K29p4PgWQQkbKQBzCs6tuyrQP12RLZdZClglq8ppnM4xLprqHu7U63W+0U6uKv7bN+S+aKJeeJoHFOH832XIfcC+3NMYKAOKUXpo/WbYjRBaLKDx9awNWz5+d1+kV/mZc1zNa27utq3LKVu13ReatuQ2D4ZxevyRpnvvlbWx3POqFRheBS4Gng391/TwHfjcWimOjId5G2CK2cbe3tnP/nnpOnMlXWYS2CMIFoam3nqgfejhR3Clke9PfXbc7cOkm/ft+2d14ZGlywVXlx6Tpue2l5NFvTk87aI8itEqvL1ZWUC1nuc1BDAWBtY3Al2VuuIXqhR3Di/71QvDTS2LJtG4vXNOd9v95ZuT5rmPfWdrtxy1Da2ju6fgcRpZIXlJY83pMZWlXIQozhRJIXdZzIN7j/+iXL1jazW4RwzvTR7groow2b2SHLOV+79bVAn32miirMtRNW9TW1trFmU0uXQ65YQlAmWQpu2mBaZ0d7V+vBcysIGvxQqHLmza+4gYWzo1ncnVYWIch1QPWf765lz8GNfCxHOyC1TISFyMSmLa2MDtrf0sa4gOZYHD2CtY0tbJeeTjGnroQ0tho2b4Wa4iXj58I75vGvzn0ZlqegRSlD/rzwl/VwIchOro0YjyFV8azyE3Wtoakicp+ILBCR97x/sVgUE1EfLEnLxtUbswwS4lSIQYUi02Bx2GBvWAFZs6k1JY1yidaa6MwyK6K+aWvG1tTz76bMFmbl+tTWEYQLwZpN3a3d7z+Qe9c9W+Ub9R54lKE0tsQz2NaZpcfZsCms5R9WDvKroN/LMKh96V//1WNfvq6hLQFLYKxtDO5xxePmcshWKWejIsJYmz+PnLLe2WN/kE2Z4wwP8/Ky8BmBtTUlFALgjzi9gXbgUODPwO2xWBQT5WXRfMMfNbamVEBrIghBWUhFqB3hlU5YjyCscH3/wXdS0ohSgAHWNwcPSnu0d4a4dVze+rAhZXuLO6tpxYYW30PYGWj3T+csiGRjGNl6BFHvgUeZZL7WTGQ77/21mzJHENIoCK9M8qugD/vFs6HHguPML50PGnpW+ve+tjwwbFyLegC+Sjm/fM210va7QcPKRJS8y5TuwlUbQ48NLWWPABikqk8BoqofqOrVwLGxWBQTEXWgB+9+tDFrGAkZLNWO8B5BWJc0UwHxF7yobpHNIdNRU+MNJz0db/ufS9Z1LYMQNkZQ6DIJWXsEOVZicbZMs8Wda37HMUYQFGcxV7Io79WBby/uwtLI1TXkb/QVIgSZ7M10/tDqeMYIogrBVncJ6iUicqGInAwMjcWimMhXR19ckn0GQFiPoKPIQpBPjyBKhZJpCmF6Ol5PJuzhSI23sAqgM0uu5doj6A0XRRi5C0G+g7jRyo/HsvosPZkcCO/lxi/A+aYRRQj8eeHv/RYi4mV0ZhCS8PNL3SO4CBgMfAuYCZwFnBOLRTGRSyXgDxm1mxeUeZ15CIFkaKL5K+yoreFM8XXHG056OhUBD4GEFOpCK4BiDxaX0Rlh0Dc/stmSa37na2Xmcl7MPOppYZgwxyvA3RMWCjk/E/7xPPGVoMJmDYX3mDOdH1OHILsQuC+PfUFVm1W1TlXPU9VTVPXleEyKh848B8Widh2DClTYlEEIH+gMLwSpYhO1ZRBNyDJNc01zDbl2+wuxEOJ2iFkIcm01VxagAQfvErosn2OLZBGCHPM73xe9ovYoo4TPlVCx64We2LH7pM+HikaUXqU/7xwhyDZYnD3vpk+szZD34RR1lpePrLWJOm8xfTKW1HuR6MugpH6PIMobvGHdvEyFLGzW0PCq4GKQPjNncEW0AhHNNRROup0VXS0wf3dZAyuuPbYvzHuYbfXRmZNqc4qvkCnYo2urMx4fX5v5sxxh+R1WRvJda6iUQlCaHoET98Th+c1PjVJpjxvSPcs+yhhBlOVfaqvLM7xUmuH8mFYtjfqa2hsiMhu4F+iaLqCqf4vFqhjQqK6UtMyNkqlhrqFMD3O4PzXcz+pvdVZkaYF61FaVQYYZk3uNH8ahu+0M/4xmp7edOpMiePrsqTPGc9XKSGYG0qmZm/CVOY50FuJezXaqZHnxMCy/w8pIeZ6juLn07qC4S0zkM+5VKJ79lXmKfKTn2/c2vf9ZD7uuKI3HirJM52e4XyUWghqgATjMt0+BfiMEnZ3RW9C59gh+fPJebGlphX+k7s/UIwh7aKrLwgeQ/CIVdaB0SBYhUKCyPLzCTRec8q5ucbcth04bw9HHHeJ8qshHja90zdppJGQfd0+zLbMQTBhWCTksvVJZDp15V0pZzssqBLn1CPIlU+u7uOM4AQ2fkMZJb/QI8hX5bC49IGVZlTLRrusMu3dRGmkHTBlB/fvB5283tALCZn3H5BqK+mbxebGk3oto5NVHc+8R1FZXUFvZ03WQeYmJkJZgyNpGZXSy/bBqaIluF5C1BbHP+OFUDA1fPzBdCD27Rw6uBHfhyjFDKqGy55Po15cdRw3OWQiyjREMzfEjqcNqKthuWC2sy+28SGR5oSw0v4u83HSurqExQyrDK50MTBtXC2nvPYW7OuITgqP2Gsf9b8PBu46Gl3I/P9IYYNoz5F3n6JB7F6XxOHF4DRMnDYeAHnNZPh+0KpCoXyj7Y5AFqvpvRbcoJjojCkF5mr+/gggrKna2B7YIM7X2KsOOhbQsy+nkqwft6KzyBFRGfas2SwU1qFIgQwsm3U5v++CdR8BCXxpBdne2d3Xdt2zNfWXKCaMGQ6bZjZ25vSW8x7ghlLeTnxBkKz9ZegTVIflV7B5BxnGpABv2Hj8U8lgjIOi9nMqQZyWWbyu4fG7PsSw/8xhoWJrX+ZGe747Ud3G8Z2Dq2BoI+D7UsEqyv6fX2Z7hWxR5fMekQCRKS1lETvFt1gAnA6tU9VuxWJWBWbNm6dy5uX8dc9F9/8Pu838eg0VGbOz3NXjt96W2wjD6Dv+1CIZlW/0sGBGZF/ZFyaiuob+mRXgnocOLfZN1o/bluY59+HR59wqeVNXCHsfDW3cFK+2+56DDxiPP/NjZnnEWi1etZ/6qTXx+9yHIrkfA6rfgjdtSz5t2LI3lI2gfsj2jx+8CLeth1Zuw3e6w6SOY+4dgI2ecBcN35IOl8/nr+1V8enQjsyaPgkGjYNBIeOb/OeH2OJ4HV4+ifd177DdjJjsOL4ct66FyMLRuZMvmJh5Y2MyZFf/omcb+X+faFxr4r8r7eh7b/TioHgZl5U6LpaKa295p45htjzK6s6FneIDP3wzr3SZleSU8dU33sUO+R4cq65e+ytiVT6Wed8j3YMP78K87ne0jruHsOS0MoZUbD94MlYNg33MChaB12knUDBkGwyZC85rw+zliR9j7FNi8rjuPPvYFFGFZ3Wom7DaDQYOGwJZ1MOkTznU0rXaufcxusHIujJ8Bq+fDGvcfwGd/CI9fAcBbnVPYNnI3Zs2Y6dy3de/CW3d32zDr32DuLc7vUTt33yuXpXv9B7tM2RXZ2ghrFkDtOGhrgcFjYNNK2PfLcPPhTuC9T4VpRzu9k1VvQM0wcMvmL9tO4T8/tyfXPraQodLC+dMHwdBxTtkbORk2LGf5umYmr/w7AGtqdmZcq2vLYVfAti1O2Hl/cvYNGgWf+AasW+z83rYZBo+Cihrnn3Y61zJsPGxpgNdvdc6rHg5Tj4TRu8KzP0nNDylH9zmNles2snyTcvC0CUjDElj+fGq44TvCoOGw2n1W9/sqvHYzAA92HMSJ5S8G57fLQx0HcNynD4DyKqd8VNdC81rueKOBKtpYyRj2lA/4bPk85z7vdRJUDYEXfh0e6RfucP7WL3Ja8v5yN+srdIyeSvljlznbh3wPWjbAkNFQM8K9pknw4YtQMxzq33XKyarXU9PY+1Tq2mrZbrtxVDUud575JY+llpmYvvmQ7+LWU6HHQoZ9moZR07mo7XKWl5/ZvfO4X8LHToORO3U9UCmccJ3jpfaOHfMLplXWMM0fZs07PYXgjL8wPIMtS199hF3LAkY5T7wegFeGruC6pW+xcuJEZn3+493HPSE46QY+2VbFn15czslH7Najn97Y2ML33v4HW6tGcF5n2nj+Z77Ldc+9EiwEx/0ShqZm69nHA//4ETz3s+6d/srtY6elxpEiBJdSDowddTfcny4Elzp/PSGYeS5HlG10Fk07du+etvmoOePW1B1b1sGCB1PtApAyOOJq57eXR9PPRHY+hF0zphDAgxc4QvCp78BB/+GkV/caV7edw6QdDmHWITOccFubUoXg2Gu7bTrwAnj4293Hdj+OXU/7YXQbPnkxbL+P89u7727ZnHzqD2DGRK6b8zCnzZwIp368x+mT33sW/vx32H4fxh33a7jZnfvx6Uu6Ay140KnETvqtIzpRWfI4NH0EJ13vNK4A2rbAi9exVSupljb45MXI4VcyEZjonde8Fn4+1fk9cT+oew0OucwRnTu/6FSGx/4C3rgd2lu5sf34rELwh/ajOe7Ii3vs/+/XHgbgt1/al4kfPQovzoMpn3bih1Qh8Gzx2OO41L+b13ULwXHXUg7QJQSXBhs27aju3w9/xxGC6V+CN12ROfUP3ffFY5fD4C++Z6wj96+aRSHqGEETqWMEq3G+UdBvaO8IcIGVu6ONZRHnngV9jKO8+B9q89x1oesjlVcxurqab392WuDhkYMdmz42cQR8mH404+sqwbvL0opJ1ZAMcQRQHmFUt7yKcw6anFu86USxK9/88s5LKwMTRg7im4f4ZSXtHqaEL/Ct5gy2nzzDqUKW/yTDEmDe+R3t2fMkSp5lSgO6rl2qBkNbIwQtwhiUTnlVz/1uGfztWTOdSewZ2JalWjtmnx2gc3BKvF2/u1rcWfIq3/vj4ZWLbOUxvc4ppRCoam5v7vRBOoLGQrxMKIuaqUFCkHuBmDRyEGT48uGMHUcCcPQ+2wcHyGJvTWW5UyE89XpPIRBh3hVHQNBwSdSvd1Xl+KJYVyVaHv7Ft0IE1cvbdLsy5XmudJ2Xeo9+c8a+sL3v8ch0D3t8yjPHGSCFVj7eNXS2hd8Hz6Zc71PXeZU99lVVD3KEIMit4U/HH4e339vnVthTxmSvir5x2O7Z7fUmGvjtLavstjHbs1BwA9CNvyLzi4o9ykxMQhD1ewQni8hw3/YIETkpFotioiPoPQIvM6M+YBJwu/IoENUVmW/7buNqef/Hx3DY7uOCA5RFnDQdVJhFGD00pPAFXV8QOfcIqlL/BhG1V5ZJBCP1CPKsTL2WY7Z7lOl4of7dQisf79o72iL0CAoVTB/evQvsEQSEL6/qud+zN0IZPX7G5MD9l3xuGp+aOibVFn+PIOWexCwEElEI0u3MsLR9IUR9DeMqVe1qw6rqRuCqWCyKiWAh8FxDUYWgyK6hyvCKS4rybd2gOIoQb849Avf+VmS4V1GvN9ODE6tryKuIstmZ4XihD3HBQuD1CNqzx1UM15CHJ/JB033T3Y5eHD1cQ1HvP6G2X3Dortz2lU+4trT3TN//O5vgRG24ZKMiy9IY3j3zynYpewQh4eL5inJMBAqBV6mUR7yUIvUIugpzri3rfNNJ2Zchy8OOpcdTnaOnsKtHkKX1E4WgiqOrdVUTvD/IlpzTdSuXbO6cXHoEuYp9sXoE7oywQLp81znmVZDPu2ufL92w8/y/K6q60++KI2KPLN2GMDxb/KLh/x21d1woQeXZj/euQWXfEIK5InKtiOzi/rsWmJftJBE5SkQWi8hSEbks4Pg3RORtEXlTRP4pInvmegFRydwjiCoExe4RDMr/3HzJVPlEHiOIwTUUlUw2Rom/UNdQNvdOJvtK7hryBotL5RqKeP1llT3jifqMhtmQTpBrKKVHEOd31XxkS8ez06srSuwa+g9gG3A3cBfOi9UXZDrBXb76euBoYE/gjICK/i+quo+qTgd+Blwb3fTcCBSCshxdQ0EUMoAXd48gZ9dQXELgPmCFDnZmo1itxcDzvFZttgfRXEOhcUV9E7ysPNw1FEVMo9jemUUIeo0sz1yXa8id5VTiWUObgR4t+izsDyxV1fcAROQu4ESg60O2qupfQGAIcS2kQcisIc/PV0gFVYivMJt/sFBCBovDw0dsF1Tk2JPx4o1hqm1qOlH8x4UKQZYlIeIcLC7UL12RixAUeJ+C4srl+sMGi6PEkW0AFrrzsdSuoWzpeNfbF1xDIvKEiIzwbY8UkceynDaB1JU46tx96XFfICLLcHoEgUtWiMj5IjJXRObW19cHBcnK52dM4IELDg4+WKyBn1yJu4UctYXfNSMmYvhithZ7m0JdQ9la9RldQwX2CAp1V/hdQ9lav3mPpQTEm6trKCh97xmN0quK0sPvN64hTwjcxld7accIxrgzhQBQ1Q0U6c1iVb1eVXfBeUHtipAwv1PVWao6a+zYzF+KCmO7YTVMnzQi+GAhrqFCiDvdqIU5Vzvyrkx7qZWViUIruILGCIq7wFzO+Fvm2cpGvo2joHhzceuEpV8WsUcG0cpZ4KyhHKaPFo1sriHXzj4ya6hTRHb0NkRkMtndOCuBSb7tiQQuutrFXcBJEe3JnyE+IRnkvLjFyJ0yn7PjgcW1YbL7wbedDyluvD3wFTLvWr2CP/lTzt+Rk2HqEW7wkId/rPuCzqBRqX93CvhwnRfWf88Gj3b3HeT8nXRAJOtT8B7SoHs2Yabzd7hbRL1u9GSffbsemRpPrnjXUOsu+DXJnYY4ZEz0OLZLGyKbsG+088YEv0HexZCIjSMv73c5tHvfDtNTw+zsHstVMKd8xvlbObh73zh3qZBd3bWSxs8IP1/KYUe3XAwZ0+3e8fJ7stubH+yWve33cZZfyBevnPrzZMqnun97+Qu5jR1UZ1pcJgDPNRQ2JXv0Ls7fie5acTEJAaqa9R9wFM47qrcBtwMfAJ/Lck4FzgK3U4Aq4F/AXmlhpvp+Hw/MzWbLzJkztSC2rFdteE917aLU/WsWqG5uUN3woeqmj1Sb67uPtTapNiwLj7P+XdX6JaqbVqeeF0bbVif9zk7V955TXfmGatPa7Oc11zu2ReWZn6leNUz1T8erbtuium5p97GtzarLnlFt2ai6rSX1WBAfvd1tt6pzP7Y29wzX0ujE29qUun/NQtX2bc55/mPN9aqNq8LT3bTauTdb1jvxbmvpGaajQ3X1fOf3hg9Ut2xQXbtYta3Vd72bs19jJtq3qb73rHMfVVXb25xrCmLdUqeMeXnatNbJNy+/G1c69nZ0REu7pVF1/fLgYxs+dO5NVBqWOfdC1bGxdVPq8W0tTlnOlbZW5znw09nplBtV5/nqaA8+t3Gl8+y1tznhPOqXdOd3R3v3/V7/vmO3l6frljppL3/BuaYodHZ2lxmP9jbVVW868XV0qK5+p9u2MLub13Vvb6yLnhdzvus8my9c55wXloaqY2dbq+rCh8PLQQQy1a+RlqEGEJHtgPOBN4BBwFpVfS7LOccAvwLKgVtU9Uci8gPXoNki8mvgCJxvaG0ALlTVdzLFme8y1Inkuf+Ff/wQDvgmHBWwqJ5hGKXhkUvhlRvhsz+Cgy7slSQLXoZaRL4KXITj3nkTOADne0AZ+2aqOgeYk7bvSt/vi6Kkb+RLb/k5DcPIi96anZSFqFZcBOwHfKCqhwIzgI1xGWUUid6a+WAYRn70kWc0qhC0qmorgIhUq+oiIMsIllF6+kYhMwyjbxN1OLzOfY/gAeAJEdmAM2BsGIZh9HOivll8svvzahF5GhgOPBqbVUZx6CPdTsMw+jY5L66hqs/GYYgRByYEhmFkp28MWRvxYD0CwzAiYEIwoDEhMAwjOyYEAxnrERiGEQETAsMwjIRjQjCgsR6BYRjZMSEYyJhryDCMCJgQGIZhJBwTAsMwjIRjQmAYhpFwTAgMwzASjgmBYRhGwjEhMAzDSDgmBIZhGAnHhMAwDCPhmBAYhmEkHBMCwzCMhGNCYBiGkXBMCAzDMBKOCYFhGEbCMSEwDMNIOCYEhmEYCceEwDAMI+GYEBiGYSQcEwLDMIyEY0JgGIaRcEwIDMMwEo4JgWEYRsIxITAMw0g4JgSGYRgJJ1YhEJGjRGSxiCwVkcsCjv+XiCwQkbdE5CkR2SlOewzDMIyexCYEIlIOXA8cDewJnCEie6YFewOYpaofA+4DfhaXPYZhGEYwcfYI9geWqup7qroNuAs40R9AVZ9W1S3u5svAxBjtMQzDMAKIUwgmACt823XuvjC+AjwSdEBEzheRuSIyt76+vogmGoZhGH1isFhEzgJmAf8bdFxVf6eqs1R11tixY3vXOMMwjAFORYxxrwQm+bYnuvtSEJEjgP8GPqOqW2O0xzAMwwggzh7Ba8BUEZkiIlXAF4HZ/gAiMgO4CThBVdfGaIthGEbfYdL+zt9xe5XWDpfYegSq2i4iFwKPAeXALar6joj8AJirqrNxXEFDgXtFBOBDVT0hLpsMwzD6BHufApMOgOGZhk17jzhdQ6jqHGBO2r4rfb+PiDN9wzCMPksfEQHoI4PFhmEYRukwITAMw0g4JgSGYRgJx4TAMAwj4ZgQGIZhJBwTAsMwjIRjQmAYhpFwTAgMwzASjgmBYRhGwjEhMAzDSDgmBIZhGAnHhMAwDCPhmBAYhmEkHBMCwzCMhGNCYBiGkXBMCAzDMBKOCYFhGEbCMSEwDMNIOCYEhmEYCceEwDAMI+GYEBiGYSQcEwLDMIyEY0JgGIaRcEwIDMMwEo4JgWEYRsIxITAMw0g4JgSGYRgJx4TAMAwj4ZgQGIZhJBwTAsMwjIRjQmAYhpFwTAgMwzASjgmBYRhGwjEhMAzDSDixCoGIHCUii0VkqYhcFnD80yLyuoi0i8ipcdpiGIZhBBObEIhIOXA9cDSwJ3CGiOyZFuxD4FzgL3HZkWjKKp2/5ZWltcMwjD5NRYxx7w8sVdX3AETkLuBEYIEXQFWXu8c6Y7Qjucw8BxpXwKe/W2pLDMPow8TpGpoArPBt17n7ckZEzheRuSIyt76+vijGJYKKavjs/0D10FJbYhhGH6ZfDBar6u9UdZaqzho7dmypzTEMwxhQxCkEK4FJvu2J7j7DMAyjDxGnELwGTBWRKSJSBXwRmB1jeoZhGEYexCYEqtoOXAg8BiwE7lHVd0TkByJyAoCI7CcidcBpwE0i8k5c9hiGYRjBxDlrCFWdA8xJ23el7/drOC4jwzAMo0T0i8FiwzAMIz5MCAzDMBKOCYFhGEbCEVUttQ05ISL1wAd5nj4GWFdEc/oDds3JwK45GRRyzTupauCLWP1OCApBROaq6qxS29Gb2DUnA7vmZBDXNZtryDAMI+GYEBiGYSScpAnB70ptQAmwa04Gds3JIJZrTtQYgWEYhtGTpPUIDMMwjDRMCAzDMBJOYoQg2/eT+ysiMklEnhaRBSLyjohc5O4fJSJPiMgS9+9Id7+IyHXufXhLRPYt7RXkh4iUi8gbIvKQuz1FRF5xr+tud8VbRKTa3V7qHp9cUsPzRERGiMh9IrJIRBaKyIEJyOP/dMv0fBG5U0RqBmI+i8gtIrJWROb79uWctyJyjht+iYick4sNiRCCiN9P7q+0A99W1T2BA4AL3Gu7DHhKVacCT7nb4NyDqe6/84Ebet/konARzqq2Hj8FfqmquwIbgK+4+78CbHD3/9IN1x/5NfCoqu4OfBzn2gdsHovIBOBbwCxV3Rsox1nKfiDm85+Ao9L25ZS3IjIKuAr4BM5ngq/yxCMSqjrg/wEHAo/5ti8HLi+1XTFd64PAkcBiYAd33w7AYvf3TcAZvvBd4frLP5wVa58CDgMeAgTnbcuK9PzGWQb9QPd3hRtOSn0NOV7vcOD9dLsHeB57n7od5ebbQ8DnBmo+A5OB+fnmLXAGcJNvf0q4bP8S0SOgiN9P7su43eEZwCvAOFX9yD20Ghjn/h4I9+JXwHeBTnd7NLBRnW9gQOo1dV2ve7zRDd+fmALUA3903WE3i8gQBnAeq+pK4OfAh8BHOPk2j4Gdz35yzduC8jwpQjDgEZGhwF+Bi1V1k/+YOk2EATFPWESOA9aq6rxS29KLVAD7Ajeo6gxgM92uAmBg5TGA69Y4EUcExwND6Ok+SQS9kbdJEYIB/f1kEanEEYE7VPVv7u41IrKDe3wHYK27v7/fi4OBE0RkOXAXjnvo18AIEfE+tOS/pq7rdY8PBxp60+AiUAfUqeor7vZ9OMIwUPMY4AjgfVWtV9U24G84eT+Q89lPrnlbUJ4nRQgG7PeTRUSAPwALVfVa36HZgDdz4BycsQNv/5fd2QcHAI2+LmifR1UvV9WJqjoZJx//oapfAp4GTnWDpV+vdx9OdcP3q5azqq4GVojINHfX4cACBmgeu3wIHCAig90y7l3zgM3nNHLN28eAz4rISLc39Vl3XzRKPUjSi4MxxwDvAsuA/y61PUW8rk/idBvfAt50/x2D4x99ClgCPAmMcsMLzgyqZcDbOLMySn4deV77IcBD7u+dgVeBpcC9QLW7v8bdXuoe37nUdud5rdOBuW4+PwCMHOh5DFwDLALmA7cB1QMxn4E7ccZB2nB6f1/JJ2+Bf3OvfylwXi422BIThmEYCScpriHDMAwjBBMCwzCMhGNCYBiGkXBMCAzDMBKOCYFhGEbCMSEwjF5ERA7xVkw1jL6CCYFhGEbCMSEwjABE5CwReVVE3hSRm9zvHzSLyC/dNfKfEpGxbtjpIvKyuz78/b6143cVkSdF5F8i8rqI7OJGP1S6vy1wh/vmrGGUDBMCw0hDRPYAvgAcrKrTgQ7gSzgLn81V1b2AZ3HWfwf4M3Cpqn4M521Pb/8dwPWq+nHgIJy3R8FZIfZinG9j7Iyzho5hlIyK7EEMI3EcDswEXnMb64NwFv3qBO52w9wO/E1EhgMjVPVZd/+twL0iUgtMUNX7AVS1FcCN71VVrXO338RZi/6fsV+VYYRgQmAYPRHgVlW9PGWnyPfTwuW7PstW3+8O7Dk0Soy5hgyjJ08Bp4rIdtD1/didcJ4Xb+XLM4F/qmojsEFEPuXuPxt4VlWbgDoROcmNo1pEBvfmRRhGVKwlYhhpqOoCEbkCeFxEynBWhbwA54Mw+7vH1uKMI4CzTPCNbkX/HnCeu/9s4CYR+YEbx2m9eBmGERlbfdQwIiIizao6tNR2GEaxMdeQYRhGwrEegWEYRsKxHoFhGEbCMSEwDMNIOCYEhmEYCceEwDAMI+GYEBiGYSSc/w9t4V5nZN11/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93474946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3418981530666351\n",
      "0.35048510487377643\n",
      "457797.0471553392\n",
      "676737.8800392216\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(history.history['accuracy']))\n",
    "print(np.mean(history.history['val_accuracy']))\n",
    "print(np.mean(history.history['loss']))\n",
    "print(np.mean(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de70fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3585978150367737\n",
      "0.29361701011657715\n",
      "1277279.625\n",
      "1553429.75\n"
     ]
    }
   ],
   "source": [
    "print(history.history['accuracy'][999])\n",
    "print(history.history['val_accuracy'][999])\n",
    "print(history.history['loss'][999])\n",
    "print(history.history['val_loss'][999])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
